#+TITLE: Labwork Remote Sensing
#+SUBTITLE: How to use and to extract information from remote sensing images for land management ?
#+DATE: 2015-2016
#+AUTHOR: Mathieu Fauvel
#+EMAIL: mathieu.fauvel@ensat.fr
#+LANGUAGE: en
#+SELECT_TAGS: sigma
#+EXCLUDE_TAGS: noexport export

#+OPTIONS:   H:3 num:t toc:2 \n:nil ::t |:t ^:nil -:t f:t *:t <:t prop:t

#+LATEX_CLASS: koma-article
#+LATEX_CLASS_OPTIONS: [a4paper,11pt,DIV=18]
#+LATEX_HEADER:\usepackage[english]{babel}\usepackage{minted}\usemintedstyle{emacs}
#+LATEX_HEADER_EXTRA:\usepackage{tikz}\usepackage{pgfplots}\usepgfplotslibrary{dateplot}\usetikzlibrary{shapes,arrows}\usepackage[]{tcolorbox}
#+LATEX_HEADER_EXTRA: \newtcolorbox[auto counter,number within=section]{work}[1][]{colback=black!5!white,colframe=black!50!white,fonttitle=\sffamily\bfseries,title=Work~\thetcbcounter: #1}
#+COLUMNS: %25ITEM %FORMATION %DURATION %SEQUENCE

* Introduction                                                        :sigma:
:PROPERTIES:
:FORMATION: Presential
:DURATION:   0:30
:SEQUENCE: 1
:END:
** Objectives of the labworks
The main objective of these labworks is to
#+BEGIN_CENTER
/be able to  use and to extract information from  remote sensing images
for land management/.
#+END_CENTER
Information  can be  any knowledge  of a  given landscape  (landcover,
land-use, humidity, ...)  that is used to understand the configuration
and/or the evolution of landscape.

In terms of  /competences/, you should be  able to master at  the end of
the sessions  the items listed in  tables [[c:1]], [[c:2]], [[c:3]],  [[c:4]] and [[c:5]].
Each of them  is organized as a  set of tasks that  should be mastered
progressively.

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth}
#+CAPTION: Choose images with properties adapted to your problematic.
#+NAME: c:1
| /Remember/   | Properties of remote sensing images.                               |
| /Understand/ | Physical meaning of each sampling of a given image.                |
| /Apply/      | Open and visualize a remote sensing image, extract its properties. |
| /Analyze/    | Describe a remote sensing image. Recognize specific object.        |
| /Evaluate/   | Choose the good image adapted to what you are looking for.         |
| /Create/     | Create a set of properties needed for your problematic.            |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth}
#+CAPTION: Compute and use spectral indices.
#+NAME: c:2
| /Remember/   | Definition of spectral indices in general and of the NDVI in particular. |
| /Understand/ | What (and why) does the NDVI emphasize.                                  |
| /Apply/      | Perform the computation of spectral indices.                             |
| /Analyze/    | Analysis of the vegetation cover using NDVI.                             |
| /Evaluate/   | Choose the right spectral index.                                         |
| /Create/     | Select from the literature a set of possible indices.                    |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth} 
#+CAPTION: Define, identify and analyze radiometric behavior.
#+NAME: c:3
| /Remember/   | Spectral signature for /vegetation/ and /water/ object.                                                   |
| /Understand/ | Histogram of images.                                                                                  |
| /Apply/      | Compute an histogram.                                                                                 |
| /Analyze/    | Extract radiometric properties of some classes.                                                       |
| /Evaluate/   | Choose relevant  spectral  bands and/or  indices for  the  segmentation of several classes.           |
| /Create/     | Perform a segmentation using radiometric statistics on one or many spectral variables and/or indices. |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth} 
#+CAPTION: Do and analyze pixel-wise classification of image
#+NAME: c:4
| /Remember/   | Definition of pixel-wise supervised classification.                                                                                                                         |
| /Understand/ | The parameters of  several classification algorithm, how  the spatial sampling of the ground truth data influence the training  and validation steps.                                 |
| /Apply/      | Classification algorithms.                                                                                                                                                            |
| /Analyze/    | Interpret the confusion matrix and the thematic map, the  quality of a ground truth.                                                                                                  |
| /Evaluate/   | Compare two classification maps/results.                                                                                                                                              |
| /Create/     | Choose the most appropriate classifier for one given  application, build good ground truth data.                                                                                      |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth} 
#+CAPTION: Define and implement a processing chain
#+NAME: c:5
| /Remember/   | How to  combine several bands, apply a given  function to train  a classifier or to predict a thematic map.                                    |
| /Understand/ | The different  inputs and outputs of  =OTB= functions, how  to use their corresponding documentation.                                            |
| /Apply/      | Apply a set of different functions in a pipeline.                                                                                              |
| /Analyze/    | Define the different processing needed to perform a given task.                                                                                |
| /Evaluate/   | Evaluate the accuracy of the given processing, check for errors.                                                                               |
| /Create/     | Shell scripts that automatize most the processes, in order to  apply them  on a large set of images  or to apply  several embedded  processes. |

** Remote sensing software
In these  labworks, [[https://www.fsf.org/][free and  open sources  softwares]] will be  used to
visualize  remote sensing  images, to  process them  and to  implement
processing  chains.  In  the  following, each  software/tools will  be
briefly described.  Interested reader can find more information on the
associated website.   In particular,  the installation process  is not
detailed. However, they  can be freely download and  installed on many
operating systems from their official website.

*** Orfeo ToolBox (OTB)
[[https://www.orfeo-toolbox.org/][OTB]] is a C++ library for remote sensing images processing. It has been
developed by the  [[https://cnes.fr/en][CNES]] (French space agency) during  the ORFEO program
to /prepare, accompany and promote the use and the exploitation of the
images derived from [[https://en.wikipedia.org/wiki/Pleiades_%28satellite%29][Pleiades satellites]] (PHR)/.  Processing tools from
OTB  are appropriated  to big  images.  When  possible, processes  are
paralyzed and tiled automatically for users. Many applications derived
from OTB and  called /OTB-Applications/ are directly usable  for most of
the common processing, they are described [[https://www.orfeo-toolbox.org/CookBook/CookBook.html][here]]. For advanced users, it
is  possible  to  develop  program  based  on  the  OTB  library  (not
considered in these labworks).
 
/Monteverdi2/ is /graphical user interface/ that allows users to visualize
and process  remote sensing images  with /OTB-Applications/. It  is also
developed by the CNES during the ORFEO program. 

*** QGIS
[[http://www.qgis.org/en/site/][QGIS]] is  a /Geographic Information System/  (GIS).  It is used  to open,
visualize  and  process  digital  map.  It  includes  several  spatial
analysis tools working mainly on vector  data. QGIS can be extended by
several plugin  ([[https://plugins.qgis.org/]]) and  modules, such  as the
OTB applications.

*** Geospatial Data Abstraction Library (GDAL)
[[http://www.gdal.org/][GDAL]]  is   a  library  for   the  processing  of  raster   and  vector
data. Similar  to OTB, it  has several  applications that can  be used
directly. For advanced users, it  is possible to develop program based
on the GDAL library (not considered in these labworks).

*** Python
[[https://www.python.org/][Pyhton]]  is   a  programming  language.  It   has  several  programming
capabilities, such as /object-oriented/, /functional programming/, /dynamic
type/  and  /memory management/  that  make  it  widely used  in  several
applications:
- Web and internet development,
- Scientific and numeric computing,
- Software development.
It has a large  number of available packages that can  be used in many
applications. For instance, it is possible to call /OTB-Applications/ or
/GDAL/ from Python.
** Sequences                           
#+ATTR_LATEX: :booktabs t
#+CAPTION: Sequences
| Days             | TimeSlot (h) |   Room |
|------------------+--------------+--------|
| [2016-09-21 Wed] |            4 | Info 1 |
| [2016-09-23 Fri] |            3 |   1003 |
| [2016-09-26 Mon] |            4 |   1003 |
| [2016-09-28 Wed] |            4 |   1003 |
| [2016-09-30 Fri] |            3 |   1003 |
| [2016-10-05 Wed] |            3 |   1003 |
|------------------+--------------+--------|
| Total            |           21 |        |
#+TBLFM: @8$2=vsum(@I..@II)

** During the labworks
For the /presential/ sequences, you won't have to do any report. But you
will have to  write your personal material on remote  sensing. You are
encouraged to write it progressively  during the sessions.  *It will be
the only  document approved for the  exam* (with those on  moodle). The
length  of each  sequence  should let  you enough  time  to write  the
report.

For  the /non  presential/  sequences,  you will  be  asked  to write  a
document  that  describe briefly  the  results  and how  you  obtained
them.  Discussion between  all groups  will  be done  during the  next
session.
* Data sets                                                           :sigma:
:PROPERTIES:
:FORMATION: Presential
:DURATION:   0
:SEQUENCE: 
:END:
** Pleiades images
These images were acquired over the  Fabas forest in 2013. Images were
acquired   the   <2013-10-12   Sat>    and   the   <2013-12-10   Tue>,
respectively. A true color composition is given in Figure [[fabas_1]].

#+CAPTION: Fabas image acquired the <2013-10-12 Sat>.
#+NAME: fabas_1
#+ATTR_LATEX: :width 0.5\textwidth
[[file:./figures/quicklook_fabas_12_10_2013.jpg]]

Images are stored using the [[https://trac.osgeo.org/geotiff/][GeoTIFF]] format.  It is an extended version
of  the TIFF  format,  which allows  to  embed geospatial  information
within the file. GeoTIFF can be read by most of the remote sensing and
GIS software.
* Visualization of remote sensing data                                :sigma:
:PROPERTIES:
:FORMATION: Presential
:DURATION:   1:10
:SEQUENCE: 1
:END:

** Vizualization of remote sensing image
The vizualisation  of remote  sensing images can  be done  either with
Monteverdi2  or QGIS[fn::  The  library =matplotlib=  of  python is  not
adapted to  visualize remote  sensing image  and should  be avoided.].
QGIS might  be a  more efficient  when it  comes to  visualize several
images, or for the vizualisation of  vector layers. It will be used in
these labworks.

Most of  the information  regarding the  vizualisation of  raster data
with         QGIS         can          be         found         online
[[http://docs.qgis.org/2.14/en/docs/user_manual/working_with_raster/raster_properties.html]].

More  generally,  to use  raster  data  with  QGIS is  described  here
[[http://docs.qgis.org/2.14/en/docs/user_manual/working_with_raster/index.html]].

In  this labwork,  a  few  properties will  be  reviewed  and you  are
encouraged to check (at least) the given references.

*** Vizualization of grayscale image
Open the image  /fabas_10_12_2013.tif/ with QGIS. The default  view is a
colour composition, with the bands/channels association given in Table
[[tab:asso]]. To start easy, we just open  one band at a time: right click
on  the  name  of  the  opened  image in  the  /Layer/  pane  et  select
/Properties/.   Then select  the tab  /Style/ and  /Band rendering/.  In the
/render type/, select /Singleband gray/ and the band you want to display.

You surely have to do /Contrast enhancement/. Check the doc for that.

#+ATTR_LATEX: :booktabs t
#+CAPTION: Bands and channels default association in QGIS (if there is not a set of specified spectral bands in the metadata).
#+NAME: tab:asso
|------+---------|
| Band | Channel |
|------+---------|
|    1 | Red     |
|    2 | Green   |
|    3 | Blue    |
|------+---------|

#+BEGIN_work
1.  Visualize  each  spectral  band  of the  data,  and  look  at  the
   differences in terms of graylevel between spectral bands.
2. Zoom in/out: use the mousse's wheel to zoom into the image. What do
   you observe ?
#+END_work
*** Vizualization of colour image
Now you  can visualize  a colour images,  by selecting  three spectral
bands among those available  from the data. Again, /Contrast
enhancement/ should be done.

#+BEGIN_work
1. Do a "true colours" and "false colours" compositions and compare what
   is easily seen on each of them.
2. Get spectral  values for several pixels  corresponding to different
   materials  (water,  grassland,  forest  and bare  soil). For that,
   use the tool /Identify features/, see
   [[http://docs.qgis.org/2.14/en/docs/user_manual/introduction/general_tools.html]]
   for detail.
3. Fill  the /collaborative spreadsheet/  with your pixel values:
   - [[https://framacalc.org/fauvel_rs_water]]
   - [[https://framacalc.org/fauvel_rs_grassland]]
   - [[https://framacalc.org/fauvel_rs_forest]] 
   - [[https://framacalc.org/fauvel_rs_baresoil]]
#+END_work
** Get data information
Before  opening a  remote sensing  data, it  is possible  to get  some
information about its  properties. For instance, using  =gdalinfo= it is
possible to extract several information.  It can be used as

#+BEGIN_SRC sh
gdalinfo fabas_10_12_2013.tif
#+END_SRC

Help  on the function  can be obtained using  the command alone or by
doing :

#+BEGIN_SRC sh
man gdalinfo
#+END_SRC

Equivalently, it is possible to get the same information using the
function =otbcli_ReadImageInfo= from the /OTB-Applications/:

#+BEGIN_SRC sh
otbcli_ReadImageInfo -in fabas_10_12_2013.tif
#+END_SRC


#+BEGIN_work
On the /Fabas/ data set, get the following information.
1. Number of lines, columns and bands,
2. Size of each pixel,
3. Numerical types for coding pixel values,
4. Position of the upper left pixel,
5. Projection.
#+END_work
* Spectral indices: /Normalized Difference Vegetation Index/            :sigma:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 01:00
:SEQUENCE: 2
:END:

Among the available  radiometric indices, only the  NDVI is considered
in this labwork. NDVI is widely used for vegetation monitoring because
it can be related to chlorophyll content and photosynthesis.

#+BEGIN_work
1) Compute  the NDVI for each  /Fabas/ image.  You can  compute the NDVI
   using several  ways, using  either /OTB-Applications/ or  the /Raster
   Calculator/
   [[http://docs.qgis.org/2.14/en/docs/user_manual/working_with_raster/raster_analysis.html#raster-calculator]].
   For a per  band analysis, both methods are  equivalent.  Using QGIS
   provides the Graphical user interface,  which can be convenient for
   processing  few images,  while  /OTB-Applications/  allow to  process
   large number of images using /shell/ programming.

   Using the raster calculator, the following formula can be used (for
   the Fabas image):

   #+BEGIN_SRC sh
   ("fabas_12_10_2013@4"-"fabas_12_10_2013@1")/("fabas_12_10_2013@4"+"fabas_12_10_2013@1")
   #+END_SRC
   
   Using    the   /OTB-Applications/,    it   is    possible   to    use
   =otbcli_BandMath=. The syntax is similar, since we need to define the
   image, the bands used and the expression of our processing:
   
   #+BEGIN_SRC sh
   otbcli_BandMath -il fabas_12_10_2013.tif -out ndvi_fabas.tif -exp "(im1b4-im1b1)/(im1b4+im1b1)"   
   #+END_SRC

2) Compare the two NDVI and explain your results.
#+END_work
* Segmentation of remote sensing images                               :sigma:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 2:00
:SEQUENCE: 2
:END:
** Radiometric analysis
#+BEGIN_work
For   the  /near   infra  red/   band  and   the  NDVI   of  the   image
[2013-10-12 Sat], do
1) Look  at the  histogram and  identify the  local maxima.   For each
   local  maximum, try  to identify  the corresponding  pixels in  the
   image,
2)   Keep track  of  the characteristics  of  each identified  maximum
   (position and width).
#+END_work
** Segmentation of 1D histogram
In  this part,  the  extraction  of image's  pixels  sharing the  same
/radiometric behavior/ is considered.  The  analysis of the histogram is
used to estimate this /behavior/.   When only one material is segmented,
the output is a  binary image (image with value =0=  or =1=), where pixels
having  value =1=  are from  the same  material.  Figure  [[fig:mask:water]]
gives  an  example  of  such   outputs.   When  several  material  are
considered, the output is an images with integer values (=1=, =2=, =3= ...),
depending on the number of materials.

#+CAPTION: Binary image for Water.
#+NAME: fig:mask:water
#+ATTR_LATEX: :width 0.65\linewidth
[[file:./../figures/quicklook_seg_eau.png]]

A usual  work-flow is proposed  in this part.  First, QGIS is  used to
analyze the data and set-up the processing (parameters /etc/). Then, the
/OTB-Applications/ are used to automatize the processing.

#+BEGIN_work
For  the /near  infra red/  band and  the NDVI,  segment the  identified
material. For  that, you need to  define interval of pixel  values for
which a  specific action  is done  (/e.g./, set  the value  to 0  or 1).
Implement the processing using the  =BandMath= application or the Raster
calculator.
#+END_work
** Graphical Modeler
For the segmentation of the NVDI, two processings are required
1) First, the computation of the NDVI from the original image,
2) Second,  the definition of  the interval  of values to  extract the
   relevant pixels.
With the graphical modeler, it is possible to define your workflow, to
automatize      complex      tasks.      Take      a      look      at
http://docs.qgis.org/2.14/en/docs/user_manual/processing/modeler.html.  

#+BEGIN_work
Define your model  to perform the segmentation of  intro three classes
of the NDVI.
#+END_work
* Classification of remote sensing images                             :sigma:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 04:00
:SEQUENCE: 3
:END:

** Introduction
The aim  of this labwork  is to  perform the classification  of remote
sensing images using supervised algorithms.  The principle is the same
than segmentation.  But  now the gray level intervals  are not defined
manually and the  definition of a radiometric behavior  is not limited
to a rectangular area in  the spectral domain.  Furthermore, since all
the computation are  done by supervised algorithms, it  is possible to
use more information than one or  two bands and the full multispectral
image can be use.  In fact, more  than one image can be used.  In this
work, the  two /Fabas/ images  will be classified: first  separately and
then conjointly.

The  OTB  proposes  various  classifiers, each  one  having  different
characteristics.  In  order to train  (or learn) the  classifier, some
labeled pixels  should be  provided. It is  possible to  construct the
ground-truth (set of labeled pixels) in different ways:
- Using GIS layer and extract the relevant information at the pixel
  level.
- Do field survey and use GPS to identify pixels.
- Do photo-interpretation when possible.
In this  works, the  ground-truth is  provided as  a vector  file, see
[[fig:gt]].   Five  classes  are  considered,  they  are  given  in  Table
[[tab:classes]].

#+CAPTION: Ground truth for the /Fabas/ image.
#+NAME: fig:gt
#+ATTR_LATEX: :width 0.75\textwidth
[[file:./../figures/label_fabas.jpg]]

#+CAPTION: Classes of interest. Numbers corresponding to the attribute in the GIS file is also given.
#+NAME: tab:classes
#+ATTR_LATEX: :booktabs t :align cccccc
| *Classes*   | Sparse vegetation | Bare soil | Woody vegetation | Water | Built up |
|-----------+-------------------+-----------+------------------+-------+----------|
| *Attribute* |                 1 |         2 |                3 |     4 |        5 |

During  this  labwork,   it  is  proposed  to  compare   in  terms  of
classification accuracy  and processing  time some of  the classifiers
proposed in OTB and all the combination of input data, /i.e./:
- K-nn, Bayes, SVM and Random Forest.
- The ground-truth  being composed  of pixels from  one date,  and two
  /concatenated/ dates.
** Getting started with OTB
There are several steps to do a classification.
1)                /Learn   the    classifier/:   It    is   done    with
   =TrainImagesClassifier=.   It takes  as inputs,  the (set  of) remote
   sensing  image(s), the  ground-truth (in  vector format),  and some
   parameters of the method.  To learn the classifier, only the pixels
   inside the  ground-truth are  used. After this  step, a  /model/ that
   contains the parameters  is saved. If asked, a  confusion matrix is
   computed.
2) /Classify the image/: Once the  classifier is learned, it is possible
   to apply the model to all the  pixels of the image.  It can be done
   with =ImageClassifier=.
3)     Compute the  accuracy of  the  thematic map  according to  some
   groundthruth. *This groundthruth should  not be spatially correlated
   with  the one  used  for  training*.  The  confusion  matrix can  be
   computed using the function =ComputeConfusionMatrix=.
   

#+BEGIN_work
This should be done for one image and one classifier only.
1) Learn the model,
2) Apply the model to classify the entire image,
3) Compute the confusion matrix and save it in a /csv/ file.
4) Open  the CSV  using a spreadsheet.   From the  confusion matrix,
 compute the following indices:
   - Global accuracy,
   - Producer accuracy,
   - User accuracy.
#+END_work
     
** Automatize the process with scripts
It  is possible  to run  directly  the /OTB-Applications/  from the  the
command line  (on linux-based  OS). This  way, it  is possible  to run
several  operations  on   one  data  set  or  on   several  data  sets
automatically.  A brief introduction to command line tools is given in
Appendix [[#sec:shell]].

The  three previous  /OTB-Applications/ are  available from  the command
line interface (CLI), same name with the prefix =otbcli_= :

- =otbcli_TrainImagesClassifier=,
- =otbcli_ImageClassifier=,
- =otbcli_ComputeConfusionMatrix=.

The same  inputs than in  QGIS should  be provided (/raster  and vector
file/,  /algorithm parameters  .../). For  instance,  if you  are in  the
repertory where the data are, learning the KNN classifier with default
parameters do the following, classifying the whole image and computing
the confusion matrix reduce to

#+BEGIN_SRC sh
otbcli_TrainImagesClassifier \
    -io.il fabas_12_10_2013.tif \
    -io.vd train_fabas.shp \
    -classifier knn \
    -io.out model.mod
otbcli_ImageClassifier \
    -in fabas_12_10_2013.tif \
    -model model.mod \
    -out fabas_classif.tif
otbcli_ComputeConfusionMatrix \
    -in fabas_classif.tif \
    -out matconf.csv \
    -ref vector \
    -ref.vector.in valid_fabas.shp
#+END_SRC

This is nothing else than what you provide in QGIS ! In the following,
we are  going to combine  Python scripts  and the OTB  Applications to
define our  processing chain. Two python  modules will be use:  [[https://docs.python.org/2/library/os.html][os]] and
[[https://docs.python.org/2/library/glob.html][glob]].  These modules  are very convenient to manage  files, folder and
to launch applications. Also, we are going to benefit Python abilities
to process strings.

Let's start with an example, to run the first application

#+BEGIN_SRC python
# Load the module
import os

# Launch the application
os.system('otbcli_TrainImagesClassifier -io.il fabas_12_10_2013.tif -io.vd train_fabas.shp -classifier knn -io.out model.mod')
os.system('otbcli_ImageClassifier -in fabas_12_10_2013.tif -model model.mod -out fabas_classif.tif')
os.system('otbcli_ComputeConfusionMatrix -in fabas_classif.tif -out matconf.csv -ref vector -ref.vector.in valid_fabas.shp')
#+END_SRC

or equivalently:

#+BEGIN_SRC python
# Load the module
import os

# Define processing
train = 'otbcli_TrainImagesClassifier -io.il fabas_12_10_2013.tif -io.vd train_fabas.shp -classifier knn -io.out model.mod' 
classify = 'otbcli_ImageClassifier -in fabas_12_10_2013.tif -model model.mod -out fabas_classif.tif'
validate = 'otbcli_ComputeConfusionMatrix -in fabas_classif.tif -out matconf.csv -ref vector -ref.vector.in valid_fabas.shp'

# Launch the application
os.system(train)
os.system(classify)
os.system(validate)
#+END_SRC

#+BEGIN_work
1) Write  the script  to learn  the model  for all  the classification
   methods and with each date.  Each time extract the confusion matrix
   and compute the global accuracy and the class average accuracy.
2) Report the results on the /collaborative spreadsheet/.
3) For  the best method  in terms of classification  accuracy, discuss
   about the errors obtained with the confusion matrix.
4)  Classify the  whole image  and  compare by  visual inspection  the
   errors with what you have inferred from the confusion matrix.
#+END_work
** Multi dates
From the  same area, two dates  are available.  It is  possible to use
them conjointly in  many ways.  Two possible  solutions are considered
here. The first one consider the second date as additional data, /i.e./,
there are twice as many pixels in the training set. For each pixel, we
have    its    reflectance    the    [2013-10-12    Sat]    and    the
[2013-12-10 Tue]. The  second one  is to  consider that  we have  the
temporal evolution of the reference.

The first approach  can be simply done by providing  the two images as
inputs  to the  training  function. The  classification  of the  whole
images  is then  done  independently (two  classification maps).   The
second  approach  necessitates to  /concatenate/  the  two dates  before
training.   The   concatenation  can   be  done  using   the  function
=otbcli_ConcatenateImages=.  The  classification of  the whole  image is
then done conjointly (only one classification map).

#+ATTR_LATEX: :booktabs t :align cclcccc
#+CAPTION: Simulated pixels from two classes 
#+NAME: tab
| Pixel          | Date             | Class      |    B |    G |    R |   IR |
|----------------+------------------+------------+------+------+------+------|
| $\mathbf{x}_1$ | [2013-10-12 Sat] | Broadleave | 0.30 | 0.40 | 0.20 | 0.80 |
| $\mathbf{x}_1$ | [2013-12-10 Tue] | Broadleave | 0.40 | 0.45 | 0.43 | 0.40 |
| $\mathbf{x}_2$ | [2013-10-12 Sat] | Conifer    | 0.29 | 0.41 | 0.18 | 0.75 |
| $\mathbf{x}_2$ | [2013-12-10 Tue] | Conifer    | 0.27 | 0.36 | 0.30 | 0.70 |
| $\mathbf{x}_3$ | [2013-10-12 Sat] | Bare soil  | 0.39 | 0.37 | 0.38 | 0.39 |
| $\mathbf{x}_3$ | [2013-12-10 Tue] | Bare soil  | 0.42 | 0.44 | 0.43 | 0.40 |

_Works_:
1)  Using  pixels from  Table  [[tab]],  plot  on spreadsheet  all  pixels
   according to both approaches.  Discuss the advantages and drawbacks
   of each  approach in terms  of how it captures  the specto-temporal
   behavior of the different classes.
2)  Perform the  classification  using both  approaches,  for all  the
   classifiers.
3) Report the results on the /collaborative spreadsheet/.   
** Influence of the spatial distribution of the learning samples
:PROPERTIES:
:FORMATION: Non Presential
:DURATION: 01:40
:SEQUENCE: 4
:DAYS:     [2016-04-01 Fri 10:20-12:00]
:END:
_Work_:

In order to evaluate the influence of the validation samples, you will
investigate  several   reference  layers  to  compute   the  confusion
matrix. Since OTB only select a few samples from all the available one
(can be  controlled with  the options  =samples.mt= and  =samples.mv=), we
need to repeat the experiment several times, to avoid bias.

Select one classifier for all the experiments. You are encouraged to
define a shell script ...
Repeat 20 times the following test
1. Learn with /train_fabas/ and compute the confusion matrix with
   /train_fabas/. Save the confusion matrix for each repetition.
2.   Learn  with  /train_fabas/  and compute  the  confusion  matrix  with
   /valid_fabas/. Save the confusion matrix for each repetition.

Compute the  average global accuracy  and the mean class  accuracy and
their standard deviation.

Discuss about the results.
* Satellite Image Time Series                                        :export:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 04:00
:SEQUENCE: 5
:DAYS:     [2016-04-01 Fri 13:30-17:30]
:END:
** Objectives
The objectives  of this part are  two-folds. First, it is  proposed to
build  a Satellite  Image Time  Series (SITS)  given a  set of  images
acquired  over  the  same  area.   Then,  we  are  going  to  classify
winter/summer crops using the SITS.

The  time series  consists  in  a set  of  FORMOSAT  images along  the
year  2012.  Figure  \ref{fig:SITS}   provide  information  about  the
acquisition date. Reference and validation samples were extracted from
the [[https://www.data.gouv.fr/fr/datasets/registre-parcellaire-graphique-2012-contours-des-ilots-culturaux-et-leur-groupe-de-cultures-majorita/][RPG]] for the same year. Table [[tab:RPG]] provides the different
classes available of these area.

#+ATTR_LATEX: :booktabs t
#+CAPTION: RPG nomenclature and conversion used in the labwork
#+NAME: tab:RPG
| Value | Label                  | Class       | Attribute |
|-------+------------------------+-------------+-----------|
|     1 | Wheat                  | Winter Crop |         1 |
|     2 | Grain maize and silage | Summer Crop |         2 |
|     3 | Barley                 | Winter Crop |         1 |
|     4 | Other cereals          | Winter Crop |         1 |
|     5 | Rapeseed               | Winter Crop |         1 |
|     6 | Sunflower              | Summer Crop |         2 |
|     7 | Other oleaginous       | Summer Crop |         2 |
|     8 | Protein crops          | Summer Crop |         2 |
|    15 | Grain leguminous       | Winter Crop |         2 |
|    16 | Fodder                 | Grassland   |         3 |
|    18 | Permanent grassland    | Grassland   |         3 |
|    19 | Temporary meadows      | Grassland   |         3 |

** Construction of the SITS
Before classifying the  SITS, you need to built it.  In these labwork,
two SITS  will be considered. One  build will all the  spectral bands,
and the other one using the NDVI only.

_Works_:
1. Compute the NDVI for each date,
2. Concatenate all the dates,
   + For  the spectral bands  (/i.e./ all the  blue bands, then  all the
     green bands ...),
   + For the NDVI
3. Using QGIS, plot the temporal profile for several objects.

#+BEGIN_LaTeX
\begin{figure}[tb]
  \centering
  \begin{tikzpicture}
    \begin{axis}[hide y axis,axis lines=middle,
      date coordinates in=x,
      xticklabel={\texttt{\month}},
      x tick label style={},
      date ZERO=2011-12-12,
      xmin=2011-12-15, 
      xmax=2013-01-15,
      ymin=-0.25,ymax=0.25,
      xtick={{2012-01-01},{2012-02-01},{2012-03-01},{2012-04-01},{2012-05-01},{2012-06-01},{2012-07-01},{2012-08-01},{2012-09-01},{2012-10-01},{2012-11-01},{2012-12-01}},clip=false]
      \addplot [blue,thick,mark=*,only marks]coordinates{
        (2012-01-12,0)
        (2012-02-18,0)
        (2012-03-07,0)
        (2012-03-27,0)
        (2012-05-03,0)
        (2012-06-20,0)
        (2012-07-07,0)
        (2012-07-17,0)
        (2012-08-10,0)
        (2012-08-22,0)
        (2012-11-01,0)
        (2012-12-15,0)
        (2012-12-31,0)
        };      
      \end{axis}
  \end{tikzpicture}
  \caption{Acquisition dates for the SITS 2012.}
  \label{fig:SITS}
\end{figure}
#+END_LaTeX

** Classification of the SITS
Two scenario will be considered in this labwork. Classification of the
whole SITS and classification of the /best date/

_Works_: (with the classifier of your choice)
1. Do the classification of the  whole SITS given the training layers,
   and compute the predicted thematic map, restricted to pixels inside
   the RPG  (use the  mask provided). Compute  classification accuracy
   using  the  validation   layer  and  report  the   results  in  the
   /collaborative spreadsheet/.
2.  Do the  classification for  each date  independently, compute  the
   classification accuracy and report the results in the /collaborative
   spreadsheet/.

** Extraction of the best couple of dates
:PROPERTIES:
:FORMATION: Non Presential
:DURATION: 01:40
:SEQUENCE: 6
:DAYS:     [2016-04-06 Wed 10:20-12:00]
:END:
We have seen in the previous part that one date is not enough to get a
correct classification rate. In that section, we are going to test all
the  possible couple  of  dates, to  find  the best  one  in terms  of
classification accuracy. 

How to do it ? Just test  all the possible combinations! Be aware that
using =t1=  and =t2= is  the same than  using =t2= and  =t1=. Here we  have 13
dates, so the  total number of couples is  . I really
hope you can use bash script now ...

The code given  figure [[code:best:dates]] might help you.  It extracts all
the  possible  couples  of files  from  a  set  of  files in  a  given
repertory, the files ended with =*m.tif=.

#+CAPTION: Bash script to get all the possible couples of files.
#+NAME: code:best:dates
#+BEGIN_figure
#+BEGIN_SRC sh
FILE=`ls *m.tif` # Get all the files that end with 'm.tif'
EFILE=''
for file in $FILE
do
    # Add  variables to  be excluded  from the  second loop:  EFILE ->
    # Exclude file
    EFILE=`echo $EFILE $file`

    # Exclude these variables from the next loop
    FILES=$FILE # Copy the variable
    for efile in $EFILE
    do
	FILES=`echo  $FILES |  sed "s/\b$efile\b//g"`  # Exclude  from
						    # FILES   all  the
						    # file  from EFILE
						    # (substitute with
						    # nothing)
    done

    # Do the process, given the couple of images
    for files in $FILES
    do
	echo Process file $file and $files
	# Add  you  code here  to  process  the data:  concatentation,
	# training and extraction of the confusion matrix
	echo ${file:17:8}${files:17:8} #  Name of the input  data : to
				       # be  use to  set  name of  the
				       # confusion matrix
    done
    echo ""
done
#+END_SRC
#+END_figure
Analyze the three best results in terms of accuracy. Interpret the
results given the classes to be classified, the geographical area and
its practical consideration (should we buy the complete SITS, or just
some periods of the years? ...)
* Dynamic Habitat Index                                              :export:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 04:00
:SEQUENCE: 7
:DAYS:     [2016-04-05 Tue 13:30-17:30]
:END:
** Introduction
In this labworks, we are going to compute several indices of habitat
dynamic's in order to define several ecozones. It is bases on the
following paper: 

#+BEGIN_QUOTE
Nicholas C. Coops, Michael A. Wulder, Dennis C. Duro, Tian Han, Sandra
Berry,  The development  of  a Canadian  dynamic  habitat index  using
multi-temporal  satellite   estimates  of  canopy   light  absorbance,
Ecological  Indicators,  Volume  8,  Issue 5,  September  2008,  Pages
754-766,                        ISSN                        1470-160X,
http://dx.doi.org/10.1016/j.ecolind.2008.01.007.
(http://www.sciencedirect.com/science/article/pii/S1470160X08000071)
#+END_QUOTE

These indicators underly vegetation dynamic, they are usually computed
in the /fraction of photosynthetically active radiation (fPAR)/ absorbed
by  the vegetation.   However these  data  are not  available for  the
labwork.  So  in this lab,  the NDVI will  be used.  The  first (easy)
part is to convert  NDVI values to fPAR like values.   Since fPAR is a
fraction, its values  are between 0 and 1. Using  band math operators,
you have  to convert the  interval range  of NDVI to  0 and 1  using a
simple linear function: $f(x)=ax+b$. You have to find $a$ and $b$ !

** Computation of the dynamic indices
The second part of the labwork  concern the computation of the dynamic
indices. Three indices have been defined:
1. The cumulative annual greenness,
2. The annual minimum cover,
3. The greenness coefficient of variation.

All can be computed using band math operators. Just do it !

_Works_:
1. Write the shell script to compute all indices.
2. Concatenate all the indices into one multiband image.

** Characterization of ecozones

Perform a  segmentation of the SITS  using the three indices  as input
values. A  primarily study suggests  the number  of ecozones is  =4= for
this area. Look at the function =otbcli_KMeansClassification= to perform
the automatic segmentation of you data.

_Works_:
1. Performs the segmentation with 4 classes and save the values of the
   estimated centroid.
2. Extract the values of the centroid and interpret their values in
   terms of habitat.
3. Do a visual validation of your results on the thematic map.
* Appendix                                                            :sigma:
** Short introduction to shell
:PROPERTIES:
:CUSTOM_ID: sec:shell
:END:
This section provides  an introduction to /shell/  programming and /shell
scripts/.   A script  is a  set of  commands, which  allows to  write a
processing chain  for a given image,  or to apply one  processing to a
set  of   images.   Of   course,  mixing   these  two   situations  is
possible. You  can find  more information  easily on  the web,  a good
starting point can be the [[https://en.wikibooks.org/wiki/Bash_Shell_Scripting][Wikibook]].

Shell is  a programming  language that is  available on  all GNU/Linux
distributions. It  can be used  directly from the  prompt (interactive
mode), or  by writing a file  with a set  of commands to be  run. This
file should start with the line

#+BEGIN_SRC sh
#!/bin/bash
#+END_SRC
In  the following,  it is  assumed  that we  are working  on the  file
=script.sh=. To insert comment inside the script, the symbol ~#~ has to be
used.

#+BEGIN_SRC sh
# This is a comment
#+END_SRC
With Linux, a file can be  /writable/, /readable/ and/or /executable/. To be
run as a script, it should be at least /executable/ by the OS. It can be
by done by running the following command:

#+BEGIN_SRC sh
chmod +x script.sh
#+END_SRC
To run it, just do

#+BEGIN_SRC sh
./script.sh
#+END_SRC

*** Basic commands
- *cd*: Change repertory. To enter a repertory, do =cd Name_Of_Repertory=.
- *ls*: List all the file in the current repertory.
- *pwd*: Return the name of the current repertory.
- *cp*: Copy a file/repertory, for instance =cp A B=.
- *mv*: Move a file to another, for instance =mv A B=.
- *mkdir*: Create a repertory, =mkdir Name_Of_Repertory=.

For instance, to get all the =tif= files in the current folder:

#+BEGIN_SRC sh
ls *tif
fabas_10_12_2013.tif  fabas_12_10_2013.tif
#+END_SRC

*** Variables
In shell, a variable is a string (not a number). It can be defined as:

#+BEGIN_SRC sh
var1='Mathieu' # Store "Mathieu" in variables "var1"
var2='Fauvel'
var3='34'
#+END_SRC

#+RESULTS:

Be  careful to  spaces: there  are no  spaces, otherwise  an error  is
returned!  A  variable is  displayed using the  =echo= function  and the
variable is accessed with the command =$=.

#+BEGIN_SRC sh
echo $var1 $var2      # print "Mathieu Fauvel"
echo "$var3 ans"      # print "33 ans"
echo '$var3 ans'      # print "$var3 ans"
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
Mathieu Fauvel
34 ans
$var3 ans
#+END_SRC

Note the  difference between the simple  quote ='= and the  double quote
="=. The  simple quote does not  evaluate the variable while  the double
quote does.

It is possible to pass parameters to the script, solely by adding them
when the  script is called.  They are  accessible using the  command =$=
following by the order number of appearance when the script is
called. Let define the =script.sh= file.

#+BEGIN_SRC sh
# ./script.sh Name FamilyName Age
echo $1 $2
echo "J ai (eu) $3 ans !"
#+END_SRC

When we do this, we have the following output:

#+BEGIN_SRC sh
chmod +x script.sh
./script.sh Mathieu Fauvel 33
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
Mathieu Fauvel
J ai (eu) 33 ans !
#+END_SRC

*** Loop
As in any programming language, loop are very useful to apply a series
of processing  to several  elements of a  sequence. The  example below
applies a processing on all /tif/ files of the current directory:

#+BEGIN_SRC sh
for i in *.tif # For all tif file
do
    cp $i ndvi_$i # create a new file and add ndvi_ at the beginning of the filename
done
#+END_SRC
*** Sequence
It is possible to define sequences of string like this:

#+BEGIN_SRC sh
for name in bayes libsvm knn rf
do
    echo $name
done
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
bayes
libsvm
knn
rf
#+END_SRC

Sequences of numbers can be defined like this:

#+BEGIN_SRC sh
for i in `seq 1 5`
do
echo $i
done
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
1
2
3
4
5
#+END_SRC
** Short introduction to Python
:PROPERTIES:
:exports:  both
:results:  output code
:END:
A     good    starting     point     is     the    following     link:
http://kitchingroup.cheme.cmu.edu/pycse/pycse.html.   Here,   I   just
review few things that are usefull  for the labwork. But python is far
more than this short introduction.
*** String
Handling  strings with  python is  very easy.  It is  possible to  add
strings together, as with number! Pay attention to spaces...

#+BEGIN_SRC python
name="Mathieu"
surname="Fauvel"
print name + surname
#+END_SRC

#+RESULTS:
#+BEGIN_SRC python
MathieuFauvel
#+END_SRC

To use numbers in strings, it is necessary to convert them, using the function =str=

#+BEGIN_SRC python
print "Bonjour j\'ai eu " + str(33) + " ans"
#+END_SRC

#+RESULTS:
#+BEGIN_SRC python
Bonjour j'ai eu 33 ans
#+END_SRC


*** Loop
It is very  easy to iterate over  a list with python. The  list can be
made of numbers, strings etc ...  Since a list is [[https://docs.python.org/2/glossary.html][iterable]], defining a
=for= loop is just:

#+BEGIN_SRC python
listeNumber = [1,2,3,4]
print listeNumber
for item in listeNumber:
    print(item)

listeString = ['knn','bayes','libsvm','rf']
print listeString
for item in listeString:
    print(item)
#+END_SRC

#+RESULTS:
#+BEGIN_SRC python
[1, 2, 3, 4]
1
2
3
4
['knn', 'bayes', 'libsvm', 'rf']
knn
bayes
libsvm
rf
#+END_SRC

* Python and Shell Codes for the labworks                          :noexport:
:PROPERTIES:
:exports:  both
:END:
** Visualization
*** Get pixels mean values on collaborative spreadsheet
*** Boxplots
** Change detection
** Classification
** Comparison of several classifier and several  data set
#+BEGIN_SRC python
import os

#+END_SRC
** Classification Multidates from tabular [[tab]]
** Simulation for section "influence of the spatial distribution of the learning samples"
#+BEGIN_SRC python
import scipy as sp
import glob

NAMES_TRAIN,NAMES_VALID = glob.glob('confu_train_*.csv'),glob.glob('confu_valid_*.csv')
NAMES_TRAIN.sort()
NAMES_VALID.sort()

oa_train,oa_valid = [],[]

for name_train,name_valid in zip(NAMES_TRAIN,NAMES_VALID):
    temp = sp.genfromtxt(name_train,delimiter=',',skip_header=2)
    oa = 100*sp.diag(temp).sum()/temp.sum()
    oa_train.append(oa)
    temp = sp.genfromtxt(name_valid,delimiter=',',skip_header=2)
    oa = 100*sp.diag(temp).sum()/temp.sum()
    oa_valid.append(oa)
    
# Print mean accuracy
res = [[sp.mean(oa_train),sp.std(oa_train)],[sp.mean(oa_valid),sp.std(oa_valid)]]
sp.savetxt('acc.csv',res,delimiter=',',fmt='%1.3f')
#+END_SRC

** Sélection du meilleurs couple de dates
** Dynamic Habitat
* TO DO                                                            :noexport:
** A compléter
- [X] Ecrire le fonctionnement des TD
- [ ] Faire un mind map
- [X] Présentation des scripts shell
- [X] Reprendres les objectifs pour les compétences plutot que pour
  les activités
- [X] Faire la carte "test" pour la spatilization
- [ ] Leur faire faire une carte sur Fabas pour François.
- [ ] Faire le script pour les résultats de classifications et multitemp
- [ ] Rajouter le détails des bandes dans la section Data sets
** Séquences plus ou moins prêtes
+ [X] Ouvertures et Visualisation d'images
+ [X] Segmentation d'images
+ [X] Spectral indices
+ [X] Construction de série temporelle
+ [X] Changes detection
+ [X] Classification of remote sensing images
+ [ ] +Python: intro aux traitements d'images+
+ [ ] Historical Maps
** Séquences en non présentielle
- Segmentation of 2D histograms ?
- Classification of images for François.
- *Influence of the spatial correlation for training/testing set*
- *Get the best dates or couple of date for the classification of SITS ?*
** A modifier
- script python, c'est de la merde :(
- Collecter l'ensemble des solutions pour les scripts
- Donner les bandes pour Fabas et les autres images
- Modifier les images quickbird pour virer la bandes zeros à la fin...

** Column view
#+BEGIN: columnview :hlines 2 :id global :skip-empty-rows t
| ITEM                                                             | FORMATION      | DURATION | SEQUENCE |
|------------------------------------------------------------------+----------------+----------+----------|
| * Introduction                                                   | Presential     |     0:30 |        1 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Data sets                                                      | Presential     |        0 |        1 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Visualization of remote sensing data                           | Presential     |     1:10 |        1 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Spectral indices: /Normalized Difference Vegetation Index/       | Presential     |    01:00 |        2 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Segmentation of remote sensing images                          | Presential     |     2:00 |        2 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Change detection: /Detection of floods/                          | Presential     |    01:00 |        2 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Classification of remote sensing images                        | Presential     |    04:00 |        3 |
|------------------------------------------------------------------+----------------+----------+----------|
| ** Influence of the spatial distribution of the learning samples | Non Presential |    01:40 |        4 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Satellite Image Time Series                                    | Presential     |    04:00 |        5 |
|------------------------------------------------------------------+----------------+----------+----------|
| ** Extraction of the best couple of dates                        | Non Presential |    01:40 |        6 |
|------------------------------------------------------------------+----------------+----------+----------|
| * Dynamic Habitat Index                                          | Presential     |    04:00 |        7 |
#+END:

#+BEGIN_SRC emacs-lisp
(setq debug-on-error t)
#+END_SRC

