#+TITLE: Labwork Remote Sensing
#+SUBTITLE: How to use and to extract information from remote sensing images for land management ?
#+DATE: \today
#+AUTHOR: Mathieu Fauvel
#+EMAIL: mathieu.fauvel@ensat.fr
#+LANGUAGE: en
#+SELECT_TAGS: sigma
#+EXCLUDE_TAGS: noexport
#+TODO: TODO INPROGRESS DONE | CANCEL 
#+OPTIONS:   H:3 num:t toc:2 \n:nil ::t |:t ^:nil -:t f:t *:t <:t prop:nil todo:nil tags:nil

#+LATEX_CLASS: koma-article
#+LATEX_CLASS_OPTIONS: [a4paper,11pt,DIV=18]
#+LATEX_HEADER:\usepackage[english]{babel}\usepackage{minted}\usemintedstyle{emacs}
#+LATEX_HEADER_EXTRA:\usepackage{tikz}\usepackage{pgfplots}\usepgfplotslibrary{dateplot}\usetikzlibrary{shapes,arrows}\usepackage[]{tcolorbox}
#+LATEX_HEADER_EXTRA: \newtcolorbox[auto counter,number within=section]{work}[1][]{colback=black!5!white,colframe=black!50!white,fonttitle=\sffamily\bfseries,title=Work~\thetcbcounter: #1}

#+COLUMNS: %25ITEM %FORMATION %DURATION %SEQUENCE %TAG

* Introduction                                                     :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION:   0:30
:SEQUENCE: 1
:END:
** Objectives of the labworks
The main objective of these labworks is to
#+BEGIN_CENTER
/be able to  use and to extract information from  remote sensing images
for land management/.
#+END_CENTER
Information  can be  any knowledge  of a  given landscape  (landcover,
land-use, humidity, ...)  that is used to understand the configuration
and/or the evolution of landscape.

In terms of  /competences/, you should be  able to master at  the end of
the sessions  the items listed in  tables [[c:1]], [[c:2]], [[c:3]],  [[c:4]] and [[c:5]].
Each of them  is organized as a  set of tasks that  should be mastered
progressively.

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth}
#+CAPTION: Choose images with properties adapted to your problematic.
#+NAME: c:1
| /Remember/   | Properties of remote sensing images.                               |
| /Understand/ | Physical meaning of each sampling of a given image.                |
| /Apply/      | Open and visualize a remote sensing image, extract its properties. |
| /Analyze/    | Describe a remote sensing image. Recognize specific object.        |
| /Evaluate/   | Choose the good image adapted to what you are looking for.         |
| /Create/     | Create a set of properties needed for your problematic.            |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth}
#+CAPTION: Compute and use spectral indices.
#+NAME: c:2
| /Remember/   | Definition of spectral indices in general and of the NDVI in particular. |
| /Understand/ | What (and why) does the NDVI emphasize.                                  |
| /Apply/      | Perform the computation of spectral indices.                             |
| /Analyze/    | Analysis of the vegetation cover using NDVI.                             |
| /Evaluate/   | Choose the right spectral index.                                         |
| /Create/     | Select from the literature a set of possible indices.                    |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth} 
#+CAPTION: Define, identify and analyze radiometric behavior.
#+NAME: c:3
| /Remember/   | Spectral signature for /vegetation/ and /water/ object.                                                   |
| /Understand/ | Histogram of images.                                                                                  |
| /Apply/      | Compute an histogram.                                                                                 |
| /Analyze/    | Extract radiometric properties of some classes.                                                       |
| /Evaluate/   | Choose relevant  spectral  bands and/or  indices for  the  segmentation of several classes.           |
| /Create/     | Perform a segmentation using radiometric statistics on one or many spectral variables and/or indices. |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth} 
#+CAPTION: Perform and discuss pixel-wise classification of image
#+NAME: c:4
| /Remember/   | Definition of pixel-wise supervised classification.                                                                                                                         |
| /Understand/ | The parameters of  several classification algorithm, how  the spatial sampling of the ground truth data influence the training  and validation steps.                                 |
| /Apply/      | Classification algorithms.                                                                                                                                                            |
| /Analyze/    | Interpret the confusion matrix and the thematic map, the  quality of a ground truth.                                                                                                  |
| /Evaluate/   | Compare two classification maps/results.                                                                                                                                              |
| /Create/     | Choose the most appropriate classifier for one given  application, build good ground truth data.                                                                                      |

#+ATTR_LATEX: :booktabs t :align lp{0.85\linewidth} 
#+CAPTION: Define and implement a processing chain
#+NAME: c:5
| /Remember/   | How to  combine several bands, apply a given  function to train  a classifier or to predict a thematic map.                                    |
| /Understand/ | The different  inputs and outputs of  =OTB= functions, how  to use their corresponding documentation.                                            |
| /Apply/      | Apply a set of different functions in a pipeline.                                                                                              |
| /Analyze/    | Define the different processing needed to perform a given task.                                                                                |
| /Evaluate/   | Evaluate the accuracy of the given processing, check for errors.                                                                               |
| /Create/     | Shell scripts that automatize most the processes, in order to  apply them  on a large set of images  or to apply  several embedded  processes. |

** Remote sensing software
In these  labworks, [[https://www.fsf.org/][free and  open sources  softwares]] will be  used to
visualize  remote sensing  images, to  process them  and to  implement
processing  chains.  In  the  following, each  software/tools will  be
briefly described.  Interested reader can find more information on the
associated website.   In particular,  the installation process  is not
detailed. However, they  can be freely download and  installed on many
operating systems from their official website.

Students  from  the  MASTER   SIGMA  -  Specialization  /AgrogÃ©omatique/
(A. Greco) has made a youtube  channel to help you in using/installing
the                        different                        softwares:
#+BEGIN_CENTER
https://www.youtube.com/channel/UCcxj3jqQVu3w4y1397l_jKQ
#+END_CENTER

*** Orfeo ToolBox (OTB)
[[https://www.orfeo-toolbox.org/][OTB]] is a C++ library for remote sensing images processing. It has been
developed by the  [[https://cnes.fr/en][CNES]] (French space agency) during  the ORFEO program
to /prepare, accompany and promote the use and the exploitation of the
images derived from [[https://en.wikipedia.org/wiki/Pleiades_%28satellite%29][Pleiades satellites]] (PHR)/.  Processing tools from
OTB  are appropriated  to big  images.  When  possible, processes  are
paralyzed and tiled automatically for users. Many applications derived
from OTB and  called /OTB-Applications/ are directly usable  for most of
the common processing, they are described [[https://www.orfeo-toolbox.org/CookBook/CookBook.html][here]]. For advanced users, it
is  possible  to  develop  program  based  on  the  OTB  library  (not
considered in these labworks).
 
/Monteverdi2/ is /graphical user interface/ that allows users to visualize
and process  remote sensing images  with /OTB-Applications/. It  is also
developed by the CNES during the ORFEO program. 

*** QGIS
[[http://www.qgis.org/en/site/][QGIS]] is  a /Geographic Information System/  (GIS).  It is used  to open,
visualize  and  process  digital  map.  It  includes  several  spatial
analysis tools working mainly on vector  data. QGIS can be extended by
several plugin  ([[https://plugins.qgis.org/]]) and  modules, such  as the
OTB applications.

*** Geospatial Data Abstraction Library (GDAL)
[[http://www.gdal.org/][GDAL]]  is   a  library  for   the  processing  of  raster   and  vector
data. Similar  to OTB, it  has several  applications that can  be used
directly. For advanced users, it  is possible to develop program based
on the GDAL library (not considered in these labworks).

*** Python
[[https://www.python.org/][Pyhton]]  is   a  programming  language.  It   has  several  programming
capabilities, such as /object-oriented/, /functional programming/, /dynamic
type/  and  /memory management/  that  make  it  widely used  in  several
applications:
- Web and internet development,
- Scientific and numeric computing,
- Software development.
It has a large  number of available packages that can  be used in many
applications. For instance, it is possible to call /OTB-Applications/ or
/GDAL/ from Python.
** Sequences                           
*** Remote Sensing - Introduction                                :sigma:2A:
#+ATTR_LATEX: :booktabs t
#+CAPTION: Sequences
| Sequences                    | Type    |   Volume | Topics                                                  |
|------------------------------+---------+----------+---------------------------------------------------------|
| [2017-09-20 Wed 13:30-17:30] | CTD     | 04:00:00 | Visualization of remote sensing data + Spectral indices |
| [2017-09-22 Fri 13:30-17:30] | CTD     | 04:00:00 | Segmentation of RS images + Floods detection            |
| [2017-09-25 Mon 13:30-17:30] | CTD     | 04:00:00 | Classification of RS images                             |
| [2017-09-27 Wed 13:30-15:30] | CTD     | 02:00:00 | Classification of RS images                             |
| [2017-09-27 Wed 15:30-17:30] | Project | 02:00:00 | Spatial distribution of pixels                          |
| [2017-09-29 Fri 13:30-16:30] | CTD     | 03:00:00 | Dynamic Habitat Index                                   |
| [2017-10-02 Mon 08:00-10:00] | EXAM    | 02:00:00 | EXAM Groupe 1 & 2                                       |
|------------------------------+---------+----------+---------------------------------------------------------|
| Total                        |         | 21:00:00 |     |       

*** Remote Sensing - Advanced                                       :sigma:
#+ATTR_LATEX: :booktabs t
#+CAPTION: Sequences
| Sequences                    | Type   |   Volume | Topics                                                |
|------------------------------+--------+----------+-------------------------------------------------------|
| [2017-10-02 Mon 10:00-12:00] | CTD    | 02:00:00 | Introduction to Scipy: array manipulation             |
| [2017-10-09 Mon 13:30-17:30] | CTD    | 04:00:00 | Template filters  1/2                                 |
| [2017-10-11 Wed 13:30-15:30] | CTD    | 02:00:00 | Template filters 2/2 + GDAL manipulation 1/2          |
| [2017-10-16 Mon 13:30-17:30] | CTD    | 04:00:00 | GDAL manipulation 2/2 + Historical Maps 1/2           |
| [2017-10-18 Wed 13:30-15:30] | Projet | 02:00:00 | Historical Maps 2/2                                   |
| [2017-10-23 Mon 13:30-17:30] | CTD    | 04:00:00 | Linking Qgis to Python - Your first processing plugin |
| [2017-11-09 Thu 08:00-10:00] | EXAM   | 02:00:00 | EXAM Groupe 1 & 2                                     |
|------------------------------+--------+----------+-------------------------------------------------------|
| Total                        |        | 20:00:00 |                                                       |
#+TBLFM: @>$3=vsum(@I$3..@II$3)*1;T
   
** During the labworks
For the /presential/ sequences, you won't have to do any report. But you
will have to  write your personal material on remote  sensing. You are
encouraged to write it progressively  during the sessions.  *It will be
the only  document approved for the  exam* (with those on  moodle). The
length  of each  sequence  should let  you enough  time  to write  the
report.

For  the /non  presential/  sequences,  you will  be  asked  to write  a
document  that  describe briefly  the  results  and how  you  obtained
them.  Discussion between  all groups  will  be done  during the  next
session.
* Data sets                                                        :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION:   0
:SEQUENCE: 
:END:
** Pleiades images
These images were acquired over the  Fabas forest in 2013. Images were
acquired   the   <2013-10-12   Sat>    and   the   <2013-12-10   Tue>,
respectively. A true color composition is given in Figure [[fabas_1]].

#+CAPTION: Fabas image acquired the [2013-10-12 Sat].
#+NAME: fabas_1
#+ATTR_LATEX: :width 0.5\textwidth 
[[file:./figures/quicklook_fabas_12_10_2013.jpg]]

Images are stored using the [[https://trac.osgeo.org/geotiff/][GeoTIFF]] format.  It is an extended version
of  the TIFF  format,  which allows  to  embed geospatial  information
within the file. GeoTIFF can be read by most of the remote sensing and
GIS software. Table [[tab:bands:pleiades]] gives the band order of the data.

#+ATTR_LATEX: :booktabs t
#+CAPTION: Bands and channels information for the Pleiades images
#+NAME: tab:bands:pleiades
|------+-----------|
| Band | Channel   |
|------+-----------|
|    1 | Red       |
|    2 | Green     |
|    3 | Blue      |
|    4 | Infra-red |
|------+-----------|

** Formosat 2 Satellite image time series 
:PROPERTIES:
:CUSTOM_ID: sec:sits
:END:

#+CAPTION: Formosat 2 image acquired the [2012-05-03 Thu].
#+NAME: sits:f2
#+ATTR_LATEX: :width 0.5\textwidth
[[file:figures/sits_f2.png]]

This time series was acquired in 2012 over the region of /Saint Lys/. It
consists  in  a  set  of   [[http://www.satimagingcorp.com/satellite-sensors/other-satellite-sensors/formosat-2/][Formosat-2]]  images  along  the  year  2012.
Figure\nbsp{}\ref{fig:SITS} provide information  about the acquisition
date and the Figure\nbsp{}[[sits:f2]] shows a false colors composition for
the  date [2012-05-03  Thu]. Table\nbsp{}[[tab:bands:formosat]]  gives the
band order of the data.

#+ATTR_LATEX: :booktabs t
#+CAPTION: Bands and channels information for the Formosat images
#+NAME: tab:bands:formosat
|------+-----------|
| Band | Channel   |
|------+-----------|
|    1 | Blue      |
|    2 | Green     |
|    3 | Red       |
|    4 | Infra-red |
|------+-----------|

#+BEGIN_EXPORT LaTeX
\begin{figure}[tb]
  \centering
  \begin{tikzpicture}
    \begin{axis}[hide y axis,axis lines=middle,
      date coordinates in=x,
      xticklabel={\texttt{\month}},
      x tick label style={},
      date ZERO=2011-12-12,
      xmin=2011-12-15, 
      xmax=2013-01-15,
      ymin=-0.25,ymax=0.25,
      xtick={{2012-01-01},{2012-02-01},{2012-03-01},{2012-04-01},{2012-05-01},{2012-06-01},{2012-07-01},{2012-08-01},{2012-09-01},{2012-10-01},{2012-11-01},{2012-12-01}},clip=false]
      \addplot [blue,thick,mark=*,only marks]coordinates{
        (2012-01-12,0)
        (2012-02-18,0)
        (2012-03-07,0)
        (2012-03-27,0)
        (2012-05-03,0)
        (2012-06-20,0)
        (2012-07-07,0)
        (2012-07-17,0)
        (2012-08-10,0)
        (2012-08-22,0)
        (2012-11-01,0)
        (2012-12-15,0)
        (2012-12-31,0)
        };      
      \end{axis}
  \end{tikzpicture}
  \caption{Acquisition dates for the SITS 2012.}
  \label{fig:SITS}
\end{figure}
#+END_EXPORT

** Historical Maps
:PROPERTIES:
:CUSTOM_ID: sec:data:hm
:END:
The figure [[fig:hm]] shows an historical map. This is a scan performed by
the [[http://www.ign.fr/][IGN]] of an old manually drawn map.

#+CAPTION: Historical Maps
#+NAME: fig:hm
#+ATTR_LATEX: :width 0.5\textwidth
[[file:figures/old_map.jpg]]

* Visualization of remote sensing data                             :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION:   1:10
:SEQUENCE: 1
:END:

** Vizualization of remote sensing image
The vizualisation  of remote  sensing images can  be done  either with
Monteverdi2  or QGIS[fn::  The  library =matplotlib=  of  python is  not
adapted to  visualize remote  sensing image  and should  be avoided.].
QGIS might  be a  more efficient  when it  comes to  visualize several
images, or for the vizualisation of  vector layers. It will be used in
these labworks.

Most of  the information  regarding the  vizualisation of  raster data
with         QGIS         can          be         found         online
[[http://docs.qgis.org/2.14/en/docs/user_manual/working_with_raster/raster_properties.html]].

More  generally,  to use  raster  data  with  QGIS is  described  here
[[http://docs.qgis.org/2.14/en/docs/user_manual/working_with_raster/index.html]].

In  this labwork,  a  few  properties will  be  reviewed  and you  are
encouraged to check (at least) the given references.

*** Vizualization of grayscale image
Open the image  /fabas_10_12_2013.tif/ with QGIS. The default  view is a
colour composition, with the bands/channels association given in Table
[[tab:asso]]. To start easy, we just open  one band at a time: right click
on  the  name  of  the  opened  image in  the  /Layer/  pane  et  select
/Properties/.   Then select  the tab  /Style/ and  /Band rendering/.  In the
/render type/, select /Singleband gray/ and the band you want to display.

You surely have to do /Contrast enhancement/. Check the doc for that.

#+ATTR_LATEX: :booktabs t
#+CAPTION: Bands and channels default association in QGIS (if there is not a set of specified spectral bands in the metadata).
#+NAME: tab:asso
|------+---------|
| Band | Channel |
|------+---------|
|    1 | Red     |
|    2 | Green   |
|    3 | Blue    |
|------+---------|

#+BEGIN_work
1.  Visualize  each  spectral  band  of the  data,  and  look  at  the
   differences in terms of graylevel between spectral bands.
2. Zoom in/out: use the mousse's wheel to zoom into the image. What do
   you observe ?
#+END_work
*** Vizualization of colour image
Now you  can visualize  a colour images,  by selecting  three spectral
bands among those available  from the data. Again, /Contrast
enhancement/ should be done.

#+BEGIN_work
1. Do a "true colours" and "false colours" compositions and compare what
   is easily seen on each of them.
2. Get spectral  values for several pixels  corresponding to different
   materials  (water,  grassland,  forest  and bare  soil). For that,
   use the tool /Identify features/, see
   [[http://docs.qgis.org/2.14/en/docs/user_manual/introduction/general_tools.html]]
   for detail.
3. Fill  the /collaborative spreadsheet/  with your pixel values:
   - [[https://framacalc.org/fauvel_rs_water]]
   - [[https://framacalc.org/fauvel_rs_grassland]]
   - [[https://framacalc.org/fauvel_rs_forest]] 
   - [[https://framacalc.org/fauvel_rs_baresoil]]
#+END_work
** Get data information
Before  opening a  remote sensing  data, it  is possible  to get  some
information about its  properties. For instance, using  =gdalinfo= it is
possible to extract several information.  It can be used as

#+BEGIN_SRC sh
gdalinfo fabas_10_12_2013.tif
#+END_SRC

Help  on the function  can be obtained using  the command alone or by
doing :

#+BEGIN_SRC sh
man gdalinfo
#+END_SRC

Equivalently, it is possible to get the same information using the
function =otbcli_ReadImageInfo= from the /OTB-Applications/:

#+BEGIN_SRC sh
otbcli_ReadImageInfo -in fabas_10_12_2013.tif
#+END_SRC


#+BEGIN_work
On the /Fabas/ data set, get the following information.
1. Number of lines, columns and bands,
2. Size of each pixel,
3. Numerical types for coding pixel values,
4. Position of the upper left pixel,
5. Projection.
#+END_work
* Spectral indices: /Normalized Difference Vegetation Index/         :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 01:00
:SEQUENCE: 2
:END:

Among the available  radiometric indices, only the  NDVI is considered
in this labwork. NDVI is widely used for vegetation monitoring because
it can be related to chlorophyll content and photosynthesis.

#+BEGIN_work
1) Compute  the NDVI for each  /Fabas/ image.  You can  compute the NDVI
   using several  ways, using  either /OTB-Applications/ or  the /Raster
   Calculator/
   [[http://docs.qgis.org/2.14/en/docs/user_manual/working_with_raster/raster_analysis.html#raster-calculator]].
   For a per  band analysis, both methods are  equivalent.  Using QGIS
   provides the Graphical user interface,  which can be convenient for
   processing  few images,  while  /OTB-Applications/  allow to  process
   large number of images using /shell/ programming.

   Using the raster calculator, the following formula can be used (for
   the Fabas image):

   #+BEGIN_SRC sh
   ("fabas_12_10_2013@4"-"fabas_12_10_2013@1")/("fabas_12_10_2013@4"+"fabas_12_10_2013@1")
   #+END_SRC
   
   Using    the   /OTB-Applications/,    it   is    possible   to    use
   =otbcli_BandMath=. The syntax is similar, since we need to define the
   image, the bands used and the expression of our processing:
   
   #+BEGIN_SRC sh
   otbcli_BandMath -il fabas_12_10_2013.tif -out ndvi_fabas.tif -exp "(im1b4-im1b1)/(im1b4+im1b1)"   
   #+END_SRC

2) Compare the NDVI obtained for each date and explain your results.
#+END_work
* Segmentation of remote sensing images                            :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 2:00
:SEQUENCE: 2
:END:
** Radiometric analysis
#+BEGIN_work
For the NDVI of the image [2013-10-12 Sat], do
1) Look  at the  histogram and  identify the  local maxima.   For each
   local  maximum, try  to identify  the corresponding  pixels in  the
   image,
2)   Keep track  of  the characteristics  of  each identified  maximum
   (position and width).
#+END_work
** Segmentation of 1D histogram
In  this part,  the  extraction  of image's  pixels  sharing the  same
/radiometric behavior/ is considered.  The  analysis of the histogram is
used to estimate this /behavior/.   When only one material is segmented,
the output is a  binary image (image with value =0=  or =1=), where pixels
having  value =1=  are from  the same  material.  Figure  [[fig:mask:water]]
gives  an  example  of  such   outputs.   When  several  material  are
considered, the output is an images with integer values (=1=, =2=, =3= ...),
depending on the number of materials.

#+CAPTION: Binary image for Water.
#+NAME: fig:mask:water
#+ATTR_LATEX: :width 0.65\linewidth
[[file:./figures/quicklook_seg_eau.png]]

A usual  work-flow is proposed  in this part.  First, QGIS is  used to
analyze the data and set-up the processing (parameters /etc/). Then, the
/OTB-Applications/ are used to automatize the processing.

#+BEGIN_work
Segment the  identified material on the  NDVI.  For that, you  need to
define interval  of pixel values for  which a specific action  is done
(/e.g./, set the  value to 0 or 1).  Implement  the processing using the
=BandMath= application.
#+END_work
** Graphical Modeler
For the segmentation of the NVDI, two processings are required
1) First, the computation of the NDVI from the original image,
2) Second,  the definition of  the interval  of values to  extract the
   relevant pixels.
With the graphical modeler, it is possible to define your workflow, to
automatize      complex      tasks.      Take      a      look      at
http://docs.qgis.org/2.14/en/docs/user_manual/processing/modeler.html.  

#+BEGIN_work
Define your model  to perform the segmentation of  intro three classes
of the NDVI.
#+END_work
* Change detection: /Detection of floods/                            :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 01:40
:SEQUENCE: 3
:END:
Change detection  in remote sensing consists  in detecting differences
between two  images, or  a set of  images.  It can  be used  to detect
changes in vegetation properties or in land cover.  It is also used in
disaster management, to detect impacted areas. In this labwork, we are
dealing with floods.  In Figure  [[fig:cd]] is shown two quickbird images,
before  and  after a  flooding.   The  objective  is to  identify  the
impacted area to provide a map of these zones

#+CAPTION: False colours images of Lhonga Leupung area (a) before and (b) after flooding.
#+NAME: fig:cd
#+BEGIN_figure :options [h]
#+BEGIN_EXPORT LaTeX 
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.45\linewidth]{figures/tsunami_before.jpg}&\includegraphics[width=0.45\linewidth]{figures/tsunami_after.jpg}\\
    (a)&(b)
  \end{tabular}
#+END_EXPORT
#+END_figure

#+BEGIN_work
1) Characterize the  impacted zones in terms  of radiometric behavior,
   /i.e./, what is the variation in terms of spectral values. And why ?
2) Define the processing chain to extract these areas.
3) Implement the processing chain with the graphical modeler.
4) _Optional_: Implement  the same processing chain  with shell scripts,
   see [[#sec:shell]].
#+END_work

#+CAPTION: Google view of the impacted area. The red square represents the area of Figure [[fig:cd]].
#+NAME: fig:larger
#+ATTR_LATEX: :width 0.75\textwidth
[[file:./figures/google_bridge.jpg]]

* Classification of remote sensing images                          :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 04:00
:SEQUENCE: 3-4
:END:

** Introduction
The aim  of this labwork  is to  perform the classification  of remote
sensing images using supervised algorithms.  The principle is the same
than segmentation.  But  now the gray level intervals  are not defined
manually and the  definition of a radiometric behavior  is not limited
to a rectangular area in  the spectral domain.  Furthermore, since all
the computation are  done by supervised algorithms, it  is possible to
use more information than one or  two bands and the full multispectral
image can be use.  In fact, more  than one image can be used.  In this
work, the  two /Fabas/ images  will be classified: first  separately and
then conjointly.

The  OTB  proposes  various  classifiers, each  one  having  different
characteristics.  In  order to train  (or learn) the  classifier, some
labeled pixels  should be  provided. It is  possible to  construct the
ground-truth (set of labeled pixels) in different ways:
- Using GIS layer and extract the relevant information at the pixel
  level.
- Do field survey and use GPS to identify pixels.
- Do photo-interpretation when possible.
In this  works, the  ground-truth is  provided as  a vector  file, see
[[fig:gt]].   Five  classes  are  considered,  they  are  given  in  Table
[[tab:classes]].

#+CAPTION: Ground truth for the /Fabas/ image.
#+NAME: fig:gt
#+ATTR_LATEX: :width 0.75\textwidth
[[file:./figures/label_fabas.jpg]]

#+CAPTION: Classes of interest. Numbers corresponding to the attribute in the GIS file is also given.
#+NAME: tab:classes
#+ATTR_LATEX: :booktabs t :align cccccc
| *Classes*   | Sparse vegetation | Bare soil | Woody vegetation | Water | Built up |
|-----------+-------------------+-----------+------------------+-------+----------|
| *Attribute* |                 1 |         2 |                3 |     4 |        5 |

During  this  labwork,   it  is  proposed  to  compare   in  terms  of
classification accuracy  and processing  time some of  the classifiers
proposed in OTB and all the combination of input data, /i.e./:
- K-nn, Bayes, SVM and Random Forest.
- The ground-truth  being composed  of pixels from  one date,  and two
  /concatenated/ dates.
** Getting started with OTB
There are several steps to do a classification.
1)                /Learn   the    classifier/:   It    is   done    with
   =TrainImagesClassifier=.   It takes  as inputs,  the (set  of) remote
   sensing  image(s), the  ground-truth (in  vector format),  and some
   parameters of the method.  To learn the classifier, only the pixels
   inside the  ground-truth are  used. After this  step, a  /model/ that
   contains the parameters  is saved. If asked, a  confusion matrix is
   computed.
2) /Classify the image/: Once the  classifier is learned, it is possible
   to apply the model to all the  pixels of the image.  It can be done
   with =ImageClassifier=.
3)     Compute the  accuracy of  the  thematic map  according to  some
   groundthruth. *This groundthruth should  not be spatially correlated
   with  the one  used  for  training*.  The  confusion  matrix can  be
   computed using the function =ComputeConfusionMatrix=.
   

#+BEGIN_work
This should be done for one image and one classifier only.
1) Learn the model,
2) Apply the model to classify the entire image,
3) Compute the confusion matrix and save it in a /csv/ file.
4) Open  the CSV  using a spreadsheet.   From the  confusion matrix,
 compute the following indices:
   - Global accuracy,
   - Producer accuracy,
   - User accuracy.
#+END_work
     
** Automatize the process with scripts (shell, python or the Graphical modeler)
:PROPERTIES:
:CUSTOM_ID: sec:classif:automatize
:END:
It  is possible  to run  directly  the /OTB-Applications/  from the  the
command line.  This way, it is  possible to run several  operations on
one  data  set  or  on  several  data  sets  automatically.   A  brief
introduction to command line tools is given in Appendix [[#sec:shell]].

The  three previous  /OTB-Applications/ are  available from  the command
line interface (CLI), same name with the prefix =otbcli_= :

- =otbcli_TrainImagesClassifier=,
- =otbcli_ImageClassifier=,
- =otbcli_ComputeConfusionMatrix=.

The same  inputs than in  QGIS should  be provided (/raster  and vector
file/,  /algorithm parameters  .../). For  instance,  if you  are in  the
directory where the data are, learning the KNN classifier with default
parameters do the following, classifying the whole image and computing
the confusion matrix reduce to

#+BEGIN_SRC sh
otbcli_TrainImagesClassifier \
    -io.il fabas_12_10_2013.tif \
    -io.vd train_fabas.shp \
    -classifier knn \
    -io.out model.mod
otbcli_ImageClassifier \
    -in fabas_12_10_2013.tif \
    -model model.mod \
    -out fabas_classif.tif
otbcli_ComputeConfusionMatrix \
    -in fabas_classif.tif \
    -out matconf.csv \
    -ref vector \
    -ref.vector.in valid_fabas.shp
#+END_SRC

This is nothing else than what you provide in QGIS ! In the following,
we are  going to combine  Python scripts  and the OTB  Applications to
define our  processing chain. Two python  modules will be use:  [[https://docs.python.org/2/library/os.html][os]] and
[[https://docs.python.org/2/library/glob.html][glob]].  These modules  are very convenient to manage  files, folder and
to launch applications. Also, we are going to benefit Python abilities
to process strings.

Let's start with an example, to run the first application

#+BEGIN_SRC python
# Load the module
import os

# Launch the application
os.system('otbcli_TrainImagesClassifier -io.il fabas_12_10_2013.tif -io.vd train_fabas.shp -classifier knn -io.out model.mod')
os.system('otbcli_ImageClassifier -in fabas_12_10_2013.tif -model model.mod -out fabas_classif.tif')
os.system('otbcli_ComputeConfusionMatrix -in fabas_classif.tif -out matconf.csv -ref vector -ref.vector.in valid_fabas.shp')
#+END_SRC

or equivalently:

#+BEGIN_SRC python
# Load the module
import os

# Define processing
train = 'otbcli_TrainImagesClassifier -io.il fabas_12_10_2013.tif -io.vd train_fabas.shp -classifier knn -io.out model.mod' 
classify = 'otbcli_ImageClassifier -in fabas_12_10_2013.tif -model model.mod -out fabas_classif.tif'
validate = 'otbcli_ComputeConfusionMatrix -in fabas_classif.tif -out matconf.csv -ref vector -ref.vector.in valid_fabas.shp'

# Launch the application
os.system(train)
os.system(classify)
os.system(validate)
#+END_SRC

Additional usefull references are  given section [[#sec:python]], take the
time to read them.

Alternatively, it  is possible to  use the /batch  processing interface/
provided  by the  graphical  modeler  of QGIS.   It  allows the  batch
execution of a model over several inputs. Take a look at the following
link for further details:

#+BEGIN_CENTER
 https://docs.qgis.org/2.14/en/docs/user_manual/processing/batch.html?highlight=batch
#+END_CENTER

According to  your preference, use one  of these techniques to  do the
following tasks:

#+BEGIN_work
1)  Write  the   script/modeler  to  learn  the  model   for  all  the
   classification methods and  with each date.  Each  time extract the
   confusion  matrix and  compute the  global accuracy  and the  class
   average accuracy.
2)   Report   the   results    on   the   /collaborative   spreadsheet/:
   [[https://framacalc.org/fauvel_res_classification]]
3) For  the best method  in terms of classification  accuracy, discuss
   about the errors obtained with the confusion matrix.
4)  Classify the  whole image  and  compare by  visual inspection  the
   errors with what you have inferred from the confusion matrix.
#+END_work
** Multi dates                                                    :noexport:
From the  same area, two dates  are available.  It is  possible to use
them conjointly in  many ways.  Two possible  solutions are considered
here. The first one consider the second date as additional data, /i.e./,
there are twice as many pixels in the training set. For each pixel, we
have    its    reflectance    the    [2013-10-12    Sat]    and    the
[2013-12-10 Tue]. The  second one  is to  consider that  we have  the
temporal evolution of the reference.

The first approach  can be simply done by providing  the two images as
inputs  to the  training  function. The  classification  of the  whole
images  is then  done  independently (two  classification maps).   The
second  approach  necessitates to  /concatenate/  the  two dates  before
training.   The   concatenation  can   be  done  using   the  function
=otbcli_ConcatenateImages=.  The  classification of  the whole  image is
then done conjointly (only one classification map).

#+ATTR_LATEX: :booktabs t :align cclcccc
#+CAPTION: Simulated pixels from two classes 
#+NAME: tab
| Pixel          | Date             | Class      |    B |    G |    R |   IR |
|----------------+------------------+------------+------+------+------+------|
| $\mathbf{x}_1$ | [2013-10-12 Sat] | Broadleave | 0.30 | 0.40 | 0.20 | 0.80 |
| $\mathbf{x}_1$ | [2013-12-10 Tue] | Broadleave | 0.40 | 0.45 | 0.43 | 0.40 |
| $\mathbf{x}_2$ | [2013-10-12 Sat] | Conifer    | 0.29 | 0.41 | 0.18 | 0.75 |
| $\mathbf{x}_2$ | [2013-12-10 Tue] | Conifer    | 0.27 | 0.36 | 0.30 | 0.70 |
| $\mathbf{x}_3$ | [2013-10-12 Sat] | Bare soil  | 0.39 | 0.37 | 0.38 | 0.39 |
| $\mathbf{x}_3$ | [2013-12-10 Tue] | Bare soil  | 0.42 | 0.44 | 0.43 | 0.40 |

_Works_:
1)  Using  pixels from  Table  [[tab]],  plot  on spreadsheet  all  pixels
   according to both approaches.  Discuss the advantages and drawbacks
   of each  approach in terms  of how it captures  the specto-temporal
   behavior of the different classes.
2)  Perform the  classification  using both  approaches,  for all  the
   classifiers.
3) Report the results on the /collaborative spreadsheet/.   
** Influence of the spatial distribution of the learning samples
:PROPERTIES:
:FORMATION: Non Presential
:DURATION: 01:00
:SEQUENCE: 4
:END:
In order to evaluate the influence of the validation samples, you will
investigate  several   reference  layers  to  compute   the  confusion
matrix. Since OTB only select a few samples from all the available one
(can be  controlled with  the options  =samples.mt= and  =samples.mv=), we
need to repeat the experiment several times, to avoid bias.

/Select one classifier  for all the experiments. You  are encouraged to
define a python/shell script or a modeler./

#+BEGIN_work
 Repeat _20_ times the following test:
1. Learn with /train_fabas/ and compute the confusion matrix with
   /train_fabas/. Save the confusion matrix for each repetition.
2. Learn  with  /train_fabas/  and compute  the  confusion  matrix  with
 /valid_fabas/. Save the confusion matrix for each repetition.
3. Compute the average global accuracy and the mean class accuracy and
   their standard deviation. /You can check the figure [[fig:code:csv:classif]] to do it automatically/.


Discuss about the results. 
#+END_work

#+CAPTION: Sample code to process a set of ~csv~ files.
#+NAME: fig:code:csv:classif
#+BEGIN_figure
#+BEGIN_SRC python
import scipy as sp
import glob
# get all the csv files that match the pattern and order the list in increasing order
NAMES_TRAIN,NAMES_VALID = glob.glob('confu_train_*.csv'),glob.glob('confu_valid_*.csv')
NAMES_TRAIN.sort()
NAMES_VALID.sort()

oa_train,oa_valid = [],[]

for name_train,name_valid in zip(NAMES_TRAIN,NAMES_VALID):
    temp = sp.genfromtxt(name_train,delimiter=',',skip_header=2) # read the file, skip the two first lines (of comments)
    oa = 100*sp.diag(temp).sum()/temp.sum() # Compute the overall accuracy
    oa_train.append(oa) # add the values to the list
    temp = sp.genfromtxt(name_valid,delimiter=',',skip_header=2)
    oa = 100*sp.diag(temp).sum()/temp.sum()
    oa_valid.append(oa)
    
# Compute mean accuracy and standard deviation and save the results
res = [[sp.mean(oa_train),sp.std(oa_train)],[sp.mean(oa_valid),sp.std(oa_valid)]]
sp.savetxt('acc.csv',res,delimiter=',',fmt='%1.3f')
#+END_SRC
#+END_figure
* Satellite Image Time Series                                            :2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 04:00
:SEQUENCE: 4-5
:DAYS:     [2016-04-01 Fri 13:30-17:30]
:END:
** Objectives
The objectives  of this part are  two-folds. First, it is  proposed to
build  a Satellite  Image Time  Series (SITS)  given a  set of  images
acquired  over  the  same  area.   Then,  we  are  going  to  classify
winter/summer crops  using the SITS. Reference  and validation samples
were extracted from the [[https://www.data.gouv.fr/fr/datasets/registre-parcellaire-graphique-2012-contours-des-ilots-culturaux-et-leur-groupe-de-cultures-majorita/][RPG]] for  the same year. Table [[tab:RPG]] provides
the different classes available of  these area. Details about the data
are given [[#sec:sits]].

#+ATTR_LATEX: :booktabs t
#+CAPTION: RPG nomenclature and conversion used in the labwork
#+NAME: tab:RPG
| Value | Label                  | Class       | Attribute |
|-------+------------------------+-------------+-----------|
|     1 | Wheat                  | Winter Crop |         1 |
|     2 | Grain maize and silage | Summer Crop |         2 |
|     3 | Barley                 | Winter Crop |         1 |
|     4 | Other cereals          | Winter Crop |         1 |
|     5 | Rapeseed               | Winter Crop |         1 |
|     6 | Sunflower              | Summer Crop |         2 |
|     7 | Other oleaginous       | Summer Crop |         2 |
|     8 | Protein crops          | Summer Crop |         2 |
|    15 | Grain leguminous       | Winter Crop |         2 |
|    16 | Fodder                 | Grassland   |         3 |
|    18 | Permanent grassland    | Grassland   |         3 |
|    19 | Temporary meadows      | Grassland   |         3 |

** Construction of the SITS
Before classifying the  SITS, you need to built it.  In these labwork,
two SITS  will be considered. One  build will all the  spectral bands,
and the other one using the NDVI only.

#+BEGIN_work
1. Compute the NDVI for each date,
2. Concatenate all the dates,
   + For  the spectral bands  (/i.e./ all the  blue bands, then  all the
     green bands ...),
   + For the NDVI
3.  Using QGIS,  plot the  temporal  profile for  several objects  and
   discuss of their shape w.r.t the phenology.
#+END_work
** Classification of the SITS
Two scenario will be considered in this labwork. Classification of the
whole SITS and classification of the /best date./

#+BEGIN_work
/With the classifier of your choice/
1. Do the classification of the  whole SITS given the training layers,
   and compute the predicted thematic map, restricted to pixels inside
   the RPG  (use the  mask provided). Compute  classification accuracy
   using  the  validation   layer  and  report  the   results  in  the
   /collaborative spreadsheet/.
2.  Do the  classification for  each date  independently, compute  the
   classification accuracy and report the results in the /collaborative
   spreadsheet/. /Tips: It can (must) be automatized .../

   [[https://framacalc.org/fauvel_res_sits]]
#+END_work
** Extraction of the best couple of dates                         :noexport:
:PROPERTIES:
:FORMATION: Non Presential
:DURATION: 01:40
:END:
We have seen in the previous part that one date is not enough to get a
correct classification rate. In that section, we are going to test all
the  possible couple  of  dates, to  find  the best  one  in terms  of
classification accuracy. 

How to do it ? Just test  all the possible combinations! Be aware that
using =t1=  and =t2= is  the same than  using =t2= and  =t1=. Here we  have 13
dates, so the  total number of couples is  . I really
hope you can use bash script now ...

The code given  figure [[code:best:dates]] might help you.  It extracts all
the  possible  couples  of files  from  a  set  of  files in  a  given
directory, the files ended with =*m.tif=.

#+CAPTION: Bash script to get all the possible couples of files.
#+NAME: code:best:dates
#+BEGIN_figure
#+BEGIN_SRC sh
FILE=`ls *m.tif` # Get all the files that end with 'm.tif'
EFILE=''
for file in $FILE
do
    # Add  variables to  be excluded  from the  second loop:  EFILE ->
    # Exclude file
    EFILE=`echo $EFILE $file`

    # Exclude these variables from the next loop
    FILES=$FILE # Copy the variable
    for efile in $EFILE
    do
	FILES=`echo  $FILES |  sed "s/\b$efile\b//g"`  # Exclude  from
						    # FILES   all  the
						    # file  from EFILE
						    # (substitute with
						    # nothing)
    done

    # Do the process, given the couple of images
    for files in $FILES
    do
	echo Process file $file and $files
	# Add  you  code here  to  process  the data:  concatentation,
	# training and extraction of the confusion matrix
	echo ${file:17:8}${files:17:8} #  Name of the input  data : to
				       # be  use to  set  name of  the
				       # confusion matrix
    done
    echo ""
done
#+END_SRC
#+END_figure
Analyze the three best results in terms of accuracy. Interpret the
results given the classes to be classified, the geographical area and
its practical consideration (should we buy the complete SITS, or just
some periods of the years? ...)
* Dynamic Habitat Index                                            :sigma:2A:
:PROPERTIES:
:FORMATION: Presential
:DURATION: 04:00
:SEQUENCE: 5
:END:
** Introduction
In this labworks, we are going to compute several indices of habitat
dynamic's in order to define several ecozones. It is bases on the
following paper: 

#+BEGIN_QUOTE
Nicholas C. Coops, Michael A. Wulder, Dennis C. Duro, Tian Han, Sandra
Berry,  The development  of  a Canadian  dynamic  habitat index  using
multi-temporal  satellite   estimates  of  canopy   light  absorbance,
Ecological  Indicators,  Volume  8,  Issue 5,  September  2008,  Pages
754-766,                        ISSN                        1470-160X,
http://dx.doi.org/10.1016/j.ecolind.2008.01.007.
(http://www.sciencedirect.com/science/article/pii/S1470160X08000071)
#+END_QUOTE

These indicators underly vegetation dynamic, they are usually computed
in the /fraction of photosynthetically active radiation (fPAR)/ absorbed
by the vegetation.  However these data  are not available.  So in this
lab, the NDVI will be used. The data is described in [[#sec:sits]].


#+BEGIN_work
The first (easy)  part is to convert NDVI values  to fPAR like values.
Since fPAR is a fraction, its values  are between 0 and 1. You have to
convert the interval  range of NDVI to  0 and 1 using  a simple linear
function: $f(x)=ax+b$. You have to find $a$ and $b$ !
#+BEGIN_EXPORT LaTeX
\begin{eqnarray*}
  f:[-1,1] &\to& [0,1]\\
  x&\mapsto&f(x)=ax+b
\end{eqnarray*}
#+END_EXPORT
#+END_work

** Construction of the SITS
Before analyzing the  SITS, you need to built it.   
#+BEGIN_work
1. Compute the NDVI for each date,
2. Convert to fPAR-like values,
3. Concatenate all the dates,
4.  Using QGIS,  plot the  temporal  profile for  several objects.
#+END_work

** Computation of the dynamic indices
The second part of the labwork  concern the computation of the dynamic
indices.   Let  us  note  the  vector   of  fPAR  values  of  pixel  i
$\mathbf{x}_i=[\mathbf{x}_i(t_1),\ldots,\mathbf{x}_i(t_d)]$.     Three
indices have been defined:
1. The cumulative annual greenness,
#+BEGIN_EXPORT LaTeX
$$CG = \sum_{j=1}^d\mathbf{x}_i(t_j)$$
#+END_EXPORT
2. The annual minimum cover,
#+BEGIN_EXPORT LaTeX
$$MC = \min_{j}\left[\mathbf{x}_i(t_1),\ldots,\mathbf{x}_i(t_j),\ldots,\mathbf{x}_i(t_d)\right]$$
#+END_EXPORT
3. The greenness coefficient of variation.
#+BEGIN_EXPORT LaTeX
$$GCV = \frac{\sigma_{\mathbf{x}_i}}{\mu_{\mathbf{x}_i}}$$
#+END_EXPORT

#+BEGIN_work
1. Write the python scripts to compute all indices.
2. Concatenate all the indices into one multiband image.
#+END_work
** Characterization of ecozones

Perform a  segmentation of the SITS  using the three indices  as input
values. A  primarily study suggests  the number  of ecozones is  =4= for
this area. Look at the function =otbcli_KMeansClassification= to perform
the automatic segmentation of you data.

#+BEGIN_work
1. Performs the segmentation with 4 classes and save the values of the
   estimated centroid.
2. Extract the values of the centroid and interpret their values in
   terms of habitat.
3. Do a visual validation of your results on the thematic map.
#+END_work
* Python for Remote Sensing data analysis                             :sigma:
** Template filters
:PROPERTIES:
:DURATION: 04:00
:FORMATION: Presential
:END:
*** Introduction

In this labwork,  images will be provided under the  =Scipy= format. How
to open  remote sensing images with  =GDAL= will be addressed  later. To
load an image using =Scipy= just do

#+BEGIN_SRC python :exports code 
import scipy as sp
image = sp.load('dataname.npy')
#+END_SRC

#+RESULTS:

In the following, you will have to write python functions (mainly
image filters). In figure [[code:skeleton]] is provided a skeleton of such function, using
simple docstring convention. You are highly encouraged to put comment
in your code !

#+BEGIN_figure
#+BEGIN_SRC python :exports code :tangle skeleton.py
def TheFilter(imin,p1=p1,p2=p2, ...):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p1 = parameter 1 of the filter, default value p1
    p2 = parameter 1 of the filter, default value p2

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """

    ## Some processing

    ## Other processing

    return imout
#+END_SRC

#+RESULTS:

#+LATEX: \caption{Skeleton of the filter}
<<code:skeleton>>
#+END_figure

#+BEGIN_work
1) With  template filters,  there are a  list of  pre-processing that
  needs to  be done  every time. Find  them out. (Here  we do  not care
  about /edge  effect/: pixels at the  border of the image  will not be
  processed)
   - check of inputs,
   - initialization of the output image,
   - ...
2) Complete  the skeleton to  have a ready-to-use function,  where you
   will just have to implement  the operation in the neighborhood. Few
   lines of codes to scan all the pixel of the images.
#+END_work

*** Template filters function
Using the previously defined skeleton, implement the following filter:
=max=, =min=,  =median=, =mean=.   You can  use methods  of scipy  array class
describe below:

[[https://docs.scipy.org/doc/numpy/reference/generated/numpy.amax.html]]

[[https://docs.scipy.org/doc/numpy/reference/generated/numpy.amin.html]]

[[https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html]]

[[https://docs.scipy.org/doc/numpy/reference/generated/numpy.median.html]]

#+BEGIN_work
1) Start with a simple template, a fixed size moving window of $3\times 3$
   pixels. Write your function.
2) Modify your function to include an input parameter that control the
   size of the moving window (only consider odd size).
3)  When  your function  is  working  correctly,  try to  improve  the
   processing   time.    You   can   use   the    module   =time=,   see
   [[https://pymotw.com/2/time/]].
4) Apply  your function  on the  Ikonos images and  try to  remove the
   noise.
   #+END_work
*** To go further
- Extend your function for multidimensional images.
- Provide function with a rectangular template (with odd size).
- For the mean filter, add a new parameter that define the number of
  /cycle/, i.e., the number of times the filter is applied iteratively
  on the image.
- Implement the  following filters  and try to  explain what  are they
  action.
  + =max(im)-im=
  + =im-min(im)=
  + =max(im)-min(im)=
** Historical map processing
This section is dedicated to the implementation of the filtering part of the following paper 
#+BEGIN_QUOTE
P-A  Herrault,  D  Sheeren,  M   Fauvel,  and  M  Paegelow.  Automatic
extraction  of  forests from  historical  maps  based on  unsupervised
classification in  the cielab  color space. In  Geographic Information
Science at the Heart of  Europe, pages 95--112. Springer International
Publishing, 2013.
#+END_QUOTE

It concerns the filtering of  historical maps, see [[#sec:data:hm]] to see
the data to be processed. The filtering consists in the application of
the consecutive filters, on every bands of the color image:
1. Local max filter,
2. Local min filter,
3. Local median filter, 
as  illustrated   in  the  (simplified)  processing   chain  shown  in
[[fig:hm]]. You should write a script that takes as arguments:
- The name of the image,
- the name of the output image,
- the size of the min/max filter,
- the size of the median filter,
an, off course, do the right processing.

#+CAPTION: Processing chain.
#+NAME: fig:hm
#+BEGIN_figure :options [h]
#+BEGIN_EXPORT LaTeX
\tikzstyle{process} = [rectangle, draw, fill=blue!20, text width=8em, text centered, rounded corners, minimum height=4em,node distance=3.5cm]
  \tikzstyle{image} = [draw, rectangle,fill=red!20, node distance=3cm, minimum height=2em]
  \tikzstyle{vector} = [draw, rectangle,fill=red!20, node distance=1.5cm, minimum height=2em]
  \tikzstyle{line} = [draw, -latex']
  \begin{tikzpicture}
    \node[image] (1) {Input Image};
    \node[process,right of =1] (2)  {Max filter};
    \node[process,right of =2]  (3) {Min filter};
    \node[process,right of =3]  (4) {Median};
    \node[process,right of =4]  (5) {Classification};
    \node[vector,above of =5]  (6) {Reference data};
    \node[vector,below of=5] (7) {Classified image};
    \path[line] (1)--(2);
    \path[line] (2)--(3);
    \path[line] (3)--(4);
    \path[line] (4)--(5);
    \path[line] (6)--(5); 
    \path[line] (5)--(7); 
  \end{tikzpicture}
#+END_EXPORT
#+END_figure

#+BEGIN_work
1. Write the main steps of the filtering:
   1. Load the image
   2. Filter the image
   3. Write the results
2. Add the necessary machinery to make a python application
   1. Add command line arguments parser (see [[#sec:argparse]])
   2. Make you function executable

      #+BEGIN_SRC sh
      chmod +x yourfunction.py      
      #+END_SRC
3. Play with it to find the best couple of parameters to remove black line in the historical map.
#+END_work
** QGIS Script
QGIS offers facilities  to call python scripts directly  from QGIS. We
are going to see how it is  possible to use our previous script, which
slight  modifications,  directly in  QGIS.  Doing  this has  two  main
advantages:
1. Let QGIS does the job for the selection and the visualization of
   the images,
2. Use QGIS pre-defined function to handle arguments of our functions.
*** Install /Script Runner/
/Script Runner/ is a QGIS plugin  that allows to integrate python script
very easily:  you don't  need to  worry about  linking your  script to
QGIS, it is  done automatically. To install it, just  do /Extensions ->
Manage and Install Plugins/ and select the plugin.

Once the plugin is installed in QGIS, you can import your scripts.
*** Creating script for QGIS and /Script Runner/
Your  script needs  slight modification  in  order to  be imported  in
/Script Runner/.   

1. Add the following modules to interact with QGIS:

   #+BEGIN_SRC python
   from PyQt4.QtCore import *
   from PyQt4.QtGui import *
   from qgis.core import *
   from qgis.gui import *
   #+END_SRC

2. First you  should define  a function  =run_script(iface)= where  the
   processing is done.  =iface= is a  python object that gives access to
   several QGIS objects  and classes.  It is used  to communicate with
   QGIS. You can  also add arguments to the function:  when the script
   is run, a  window will be automatically created to  ask you to fill
   the value  of each parameter. For  instance, if you need  to define
   bands corresponding to infrared and red  and the name of the output
   file:

  #+BEGIN_SRC python
  def run_script(iface,IR,R,data_name)
  #+END_SRC

3. The  second modification  need is to  get the name  of the  data of
   current layer in QGIS. It is done using =iface= object:

   #+BEGIN_SRC python
   layer = iface.activeLayer() # Get the current layer
   name = layer.dataProvider().dataSourceUri() # Get the path of the layer
   #+END_SRC

   Then, once the processed file has  been saved on the hard drive, it
   is possible  to load directly  the file  into QGIS, again  by using
   =iface=:

   #+BEGIN_SRC python
   raster_lyr = iface.addRasterLayer('name_of_the_data','name_of_the_layer')
   #+END_SRC

4. The  last modification is not  mandatory, but it will  simplify the
   use of  your script. Don't  use =import=,  but directly put  all your
   additional functions before the =run_script= function.


#+BEGIN_work
Make the your script and use it from QGIS.
#+END_work
* Appendix                                                         :sigma:2A:
** Short introduction to shell
:PROPERTIES:
:CUSTOM_ID: sec:shell
:END:
This section provides  an introduction to /shell/  programming and /shell
scripts/.   A script  is a  set of  commands, which  allows to  write a
processing chain  for a given image,  or to apply one  processing to a
set  of   images.   Of   course,  mixing   these  two   situations  is
possible. You  can find  more information  easily on  the web,  a good
starting point can be the [[https://en.wikibooks.org/wiki/Bash_Shell_Scripting][Wikibook]].

Shell is  a programming  language that is  available on  all GNU/Linux
distributions. It  can be used  directly from the  prompt (interactive
mode), or  by writing a file  with a set  of commands to be  run. This
file should start with the line

#+BEGIN_SRC sh
#!/bin/bash
#+END_SRC
In  the following,  it is  assumed  that we  are working  on the  file
=script.sh=. To insert comment inside the script, the symbol ~#~ has to be
used.

#+BEGIN_SRC sh
# This is a comment
#+END_SRC
With Linux, a file can be  /writable/, /readable/ and/or /executable/. To be
run as a script, it should be at least /executable/ by the OS. It can be
by done by running the following command:

#+BEGIN_SRC sh
chmod +x script.sh
#+END_SRC
To run it, just do

#+BEGIN_SRC sh
./script.sh
#+END_SRC

*** Basic commands
- *cd*: Change directory. To enter a directory, do =cd Name_Of_Directory=.
- *ls*: List all the file in the current directory.
- *pwd*: Return the name of the current directory.
- *cp*: Copy a file/directory, for instance =cp A B=.
- *mv*: Move a file to another, for instance =mv A B=.
- *mkdir*: Create a directory, =mkdir Name_Of_Directory=.

For instance, to get all the =tif= files in the current folder:

#+BEGIN_SRC sh
ls *tif
fabas_10_12_2013.tif  fabas_12_10_2013.tif
#+END_SRC

*** Variables
In shell, a variable is a string (not a number). It can be defined as:

#+BEGIN_SRC sh :session toy
var1='Mathieu' # Store "Mathieu" in variables "var1"
var2='Fauvel'
var3='34'
#+END_SRC

#+RESULTS:

Be  careful to  spaces: there  are no  spaces, otherwise  an error  is
returned!  A  variable is  displayed using the  =echo= function  and the
variable is accessed with the command =$=.

#+BEGIN_SRC sh :exports both :session toy :results code
echo $var1 $var2      # print "Mathieu Fauvel"
echo "$var3 ans"      # print "33 ans"
echo '$var3 ans'      # print "$var3 ans"
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
Mathieu Fauvel
34 ans
$var3 ans
#+END_SRC

Note the  difference between the simple  quote ='= and the  double quote
="=. The  simple quote does not  evaluate the variable while  the double
quote does.

It is possible to pass parameters to the script, solely by adding them
when the  script is called.  They are  accessible using the  command =$=
following by the order number of appearance when the script is
called. Let define the =script.sh= file.

#+BEGIN_SRC sh :tangle script.sh :exports code
# ./script.sh Name FamilyName Age
echo $1 $2
echo "J ai (eu) $3 ans !"
#+END_SRC

When we do this, we have the following output:

#+BEGIN_SRC sh :exports both :results code
chmod +x script.sh
./script.sh Mathieu Fauvel 33
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
Mathieu Fauvel
J ai (eu) 33 ans !
#+END_SRC

*** Loop
As in any programming language, loop are very useful to apply a series
of processing  to several  elements of a  sequence. The  example below
applies a processing on all /tif/ files of the current directory:

#+BEGIN_SRC sh
for i in *.tif # For all tif file
do
    cp $i ndvi_$i # create a new file and add ndvi_ at the beginning of the filename
done
#+END_SRC
*** Sequence
It is possible to define sequences of string like this:

#+BEGIN_SRC sh :exports both :results code
for name in bayes libsvm knn rf
do
    echo $name
done
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
bayes
libsvm
knn
rf
#+END_SRC

Sequences of numbers can be defined like this:

#+BEGIN_SRC sh :exports both :results code
for i in `seq 1 5`
do
echo $i
done
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
1
2
3
4
5
#+END_SRC
** Short introduction to Python
:PROPERTIES:
:CUSTOM_ID: sec:python
:header-args: :exports both 
:header-args+: :results output
:END:
A     good    starting     point     is     the    following     link:
http://kitchingroup.cheme.cmu.edu/pycse/pycse.html.   Here,   I   just
review few things that are usefull  for the labwork. But python is far
more than this short introduction.
*** String
Handling  strings with  python is  very easy.  It is  possible to  add
strings together, as with number! Pay attention to spaces...

#+BEGIN_SRC python
name="Mathieu"
surname="Fauvel"
print name + surname
#+END_SRC

#+RESULTS:
: MathieuFauvel

To use numbers in strings, it is necessary to convert them, using the function =str=

#+BEGIN_SRC python
print "Bonjour j\'ai eu " + str(33) + " ans"
#+END_SRC

#+RESULTS:
: Bonjour j'ai eu 33 ans

*** Loop
It is very  easy to iterate over  a list with python. The  list can be
made of numbers, strings etc ...  Since a list is [[https://docs.python.org/2/glossary.html][iterable]], defining a
=for= loop is just:

#+BEGIN_SRC python
listeNumber = [1,2,3,4]
print listeNumber
for item in listeNumber:
    print(item)

listeString = ['knn','bayes','libsvm','rf']
print listeString
for item in listeString:
    print(item)
#+END_SRC

#+RESULTS:
#+BEGIN_SRC python
[1, 2, 3, 4]
1
2
3
4
['knn', 'bayes', 'libsvm', 'rf']
knn
bayes
libsvm
rf
#+END_SRC

*** Glob
The [[https://docs.python.org/2/library/glob.html][glob]] module finds all the  path-names matching a given pattern. It
uses standard Unix (shell) path  expansion rules. However, results are
returned in arbitrary order and therefore sometimes ordering operation
is necessary. It returns a list  of pathnames, or a iterator which can
be useful  for large  processing. Below  some examples  to see  how it
works. First, check what is in my /figures/ directory:

#+BEGIN_SRC sh
ls figures/
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
google_bridge.jpg
label_fabas.jpg
label_fabas.jpgw
old_map.jgw
old_map.jpg
pixel.pdf
quicklook_fabas_10_12_2013.jpg
quicklook_fabas_12_10_2013.jpg
quicklook_seg_eau.png
sits_f2.pgw
sits_f2.png
take5spot5.png
tsunami_after.jpg
tsunami_before.jpg
#+END_SRC

If we want to get all the files, we just need to do

#+BEGIN_SRC python
import glob

files = glob.glob("figures/*")
for files_ in files:
    print files_
#+END_SRC

#+RESULTS:
#+BEGIN_SRC python
figures/sits_f2.png
figures/quicklook_fabas_12_10_2013.jpg
figures/tsunami_after.jpg
figures/take5spot5.png
figures/sits_f2.pgw
figures/quicklook_fabas_10_12_2013.jpg
figures/pixel.pdf
figures/label_fabas.jpg
figures/tsunami_before.jpg
figures/old_map.jpg
figures/quicklook_seg_eau.png
figures/label_fabas.jpgw
figures/old_map.jgw
figures/google_bridge.jpg
#+END_SRC

If we only want the /png/ files:

#+BEGIN_SRC python
import glob

files = glob.glob("figures/*.png")
for files_ in files:
    print files_
#+END_SRC

#+RESULTS:
#+BEGIN_SRC python
figures/sits_f2.png
figures/take5spot5.png
figures/quicklook_seg_eau.png
#+END_SRC

The iterator is =iglob=, it does the same job than =glob=, but without storing all the results simultaneously.

#+BEGIN_SRC python
import glob

for files_ in glob.iglob("figures/*.png"):
    print files_
#+END_SRC

#+RESULTS:
#+BEGIN_SRC python
figures/sits_f2.png
figures/take5spot5.png
figures/quicklook_seg_eau.png
#+END_SRC

*** Argparse
:PROPERTIES:
:custom_ID: sec:argparse
:END:
Argparse (https://docs.python.org/3.6/library/argparse.html) is module
to parse  options and  arguments from  the command-line  interface. It
defines what  are the  mandatory argument,  generates help  and usages
messages and errors at runtime. 

For instance,  suppose we have  a function that needs  two parameters:
the  name  of a  multispectral  file  and  the  size of  the  template
filter. Argparse handles everything:

#+BEGIN_SRC python :tangle app.py
import argparse

# Initialization of the filter
parser = argparse.ArgumentParser()

# Add arguments
parser.add_argument("-in",dest="image",help="Image to be processed",type=str)
parser.add_argument("-p",help="Size of the template",type=int,default=1)

args = parser.parse_args()

print args.image
print args.p
#+END_SRC

* Python and Shell Codes for the labworks                          :noexport:
:PROPERTIES:
:exports:  both
:END:
** Visualization
*** Get pixels mean values on collaborative spreadsheet
#+BEGIN_SRC python :tangle visu_mean_pixel.py
import scipy as sp
import urllib2
import time
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')

URL = ['https://framacalc.org/fauvel_rs_water','https://framacalc.org/fauvel_rs_grassland','https://framacalc.org/fauvel_rs_forest','https://framacalc.org/fauvel_rs_baresoil']
LABEL = ['Water','Grassland','Forest','Bare soil']
COLOR = ['b','g','r','m']

for i,url in enumerate(URL):
    try:
        with open('temp.csv','wb') as file:
            file.write(urllib2.urlopen(url+'.csv').read())
        data = sp.genfromtxt('temp.csv',delimiter=',',skip_header=1)
        os.remove("temp.csv")

        m,s=data.mean(axis=0),data.std(axis=0)

        plt.figure()
        plt.plot(range(1,5),m,'k',lw=2)
        plt.title(LABEL[i])
        plt.ylim([0,1000])
        plt.draw()
    except KeyboardInterrupt:
        exit()
    except:
        print("Error in reading class {0}".format(LABEL[i]))

plt.show()
#+END_SRC

#+RESULTS:
: None

*** Boxplots
#+BEGIN_SRC python
import scipy as sp
import urllib2
import time
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')

URL = ['https://framacalc.org/fauvel_rs_water','https://framacalc.org/fauvel_rs_grassland','https://framacalc.org/fauvel_rs_forest','https://framacalc.org/fauvel_rs_baresoil']
LABEL = ['Water','Grassland','Forest','Bare soil']

fig=plt.figure()
for i,url in enumerate(URL):
    try:
        with open('temp.csv','wb') as file:
            file.write(urllib2.urlopen(url+'.csv').read())
        data = sp.genfromtxt('temp.csv',delimiter=',',skip_header=1)
        os.remove("temp.csv")
        
        ax = fig.add_subplot(4,1,i+1)
        plt.boxplot(data)
        ax.set_title(LABEL[i])
        ax.set_ylim([0,1000])
    except KeyboardInterrupt:
        exit()
    except:
            print("Error in reading class {0}".format(LABEL[i]))
plt.show()
#+END_SRC

#+RESULTS:
: None

** Change detection
#+BEGIN_SRC sh
#!/bin/bash

# NDVI BEFORE
otbcli_BandMath -il tsunami_before.dat -out ndvi_before.tif -exp "(im1b4-im1b3)/(im1b4+im1b3)"

# NDVI AFTER
otbcli_BandMath -il tsunami_after.dat -out ndvi_after.tif -exp "(im1b4-im1b3)/(im1b4+im1b3)"

# Diff NDVI
otbcli_BandMath -il ndvi_after.tif ndvi_before.tif -out temp.tif -exp "im1b1-im2b1"
otbcli_BandMath -il temp.tif -out diff.tif -exp "(im1b1>1?1:im1b1)" # if(im1b1>1,1,im1b1)

# Seuil
otbcli_BandMath -il diff.tif -out floods.tif -exp "(im1b1<-0.4?1:0)" # if(im1b1<-0.4,1,im1b1)


#+END_SRC
** Comparison of several classifier and several  data set
#+BEGIN_SRC python
import scipy as sp
import urllib2
import time
import os
import matplotlib.pyplot as plt
import matplotlib
#matplotlib.style.use('ggplot')

url = 'https://framacalc.org/fauvel_res_classification'
classifier =['RF','GMM','KNN']

# Read the file
with open('temp.csv','wb') as file:
    file.write(urllib2.urlopen(url+'.csv').read())
data = sp.genfromtxt('temp.csv',delimiter=',',skip_header=2)
os.remove("temp.csv")

index = sp.arange(3)
bar_width = 0.35
opacity = 0.4
error_config = {'ecolor': '0.3','lw':2,'capsize':5, 'capthick':2}

# Compute the statistics
m,s=sp.nanmean(data,axis=0),sp.nanstd(data,axis=0)
for i in xrange(3):
    plt.figure()
    plt.bar(index,m[i*3:i*3+3],width=bar_width,alpha=opacity,color='b',yerr=s[i*3:i*3+3],error_kw=error_config)
    plt.xticks(index+bar_width/2,classifier)
    plt.axis([-0.5, 3.5, 75, 100])
    plt.grid('on')
plt.show()
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh
for name in fabas*.tif
do
    for classifier in bayes svm rf knn
    do
	# Train
	otbcli_TrainImagesClassifier -io.il ${name} io.vd train_fabas.shp -io.out model.txt -classifier ${classifier}

	# Predict
	otbcli_ImageClassifier -in ${name} -model model.txt -out classif.tif
	
	# Compute confusion
	otbcli_ComputeConfusionMatrix -in classif.tif -ref vector -ref.vector.in valid_fabas.shp -out confu_${classifier}_${name%%.tif}.csv
    done
done
rm model.txt classif.tif
#+END_SRC
** Classification Multidates from tabular [[tab]]                     :noexport:
#+NAME: Addition
#+BEGIN_SRC python :var tab=tab :results output
import matplotlib.pyplot as plt

plt.figure()
for i,t in enumerate(tab):
    plt.plot(range(1,5),t[3:],label='p'+str(i+1))

plt.legend()
plt.show()
#+END_SRC

#+RESULTS: Addition

#+NAME: Concatenation
#+BEGIN_SRC python :var tab=tab :results output
import matplotlib.pyplot as plt
import scipy as sp
plt.figure()
x =sp.zeros((3,8))
for i in range(3):
    x[i,:4]=tab[2*i][3:]
    x[i,4:]=tab[2*i+1][3:]
    plt.plot(range(1,9),x[i,:],label='p'+str(i+1))

plt.legend()
plt.show()
#+END_SRC

#+RESULTS: Concatenation
** Simulation for section "influence of the spatial distribution of the learning samples"
#+BEGIN_SRC python
import scipy as sp
import glob

NAMES_TRAIN,NAMES_VALID = glob.glob('confu_train_*.csv'),glob.glob('confu_valid_*.csv')
NAMES_TRAIN.sort()
NAMES_VALID.sort()

oa_train,oa_valid = [],[]

for name_train,name_valid in zip(NAMES_TRAIN,NAMES_VALID):
    temp = sp.genfromtxt(name_train,delimiter=',',skip_header=2)
    oa = 100*sp.diag(temp).sum()/temp.sum()
    oa_train.append(oa)
    temp = sp.genfromtxt(name_valid,delimiter=',',skip_header=2)
    oa = 100*sp.diag(temp).sum()/temp.sum()
    oa_valid.append(oa)
    
# Print mean accuracy
res = [[sp.mean(oa_train),sp.std(oa_train)],[sp.mean(oa_valid),sp.std(oa_valid)]]
sp.savetxt('acc.csv',res,delimiter=',',fmt='%1.3f')
#+END_SRC

** SÃ©lection du meilleurs couple de dates
#+BEGIN_SRC sh
# Compute the NDVI
for name in Sud*.tif
do
    otbcli_BandMath -il ${name} -out ndvi_${name} -exp "(im1b4-im1b3)/(im1b4+im1b3)" -progress 0
done

# Compute the classification accuracy for each couple of dates
FILE=`ls ndvi_*m.tif` # Get all the files that end with 'm.tif'
EFILE=''
for file in $FILE
do
    # Add  variables to  be excluded  from the  second loop:  EFILE ->
    # Exclude file
    EFILE=`echo $EFILE $file`

    # Exclude these variables from the next loop
    FILES=$FILE # Copy the variable
    for efile in $EFILE
    do
	FILES=`echo  $FILES |  sed "s/\b$efile\b//g"`  # Exclude  from
						    # FILES   all  the
						    # file  from EFILE
						    # (substitute with
						    # nothing)
    done

    # Do the process, given the couple of images
    for files in $FILES
    do
	# Concatenation
	otbcli_ConcatenateImages -il $file $files -out ndvi_concat.tif -progress 0
	
	# Train
	otbcli_TrainImagesClassifier -io.il ndvi_concat.tif -io.vd rpg_pur_train.shp  -io.out model -classifier rf -progress 0 

	# Classify the image
	otbcli_ImageClassifier -in ndvi_concat.tif -model model -out classif.tif -progress 0

	# Confusion
	otbcli_ComputeConfusionMatrix -in classif.tif -out confu_${file:22:8}_${files:22:8}.csv -ref vector -ref.vector.in rpg_purs_validation.shp -progress 0
		
    done
done

#+END_SRC

#+BEGIN_SRC python
import scipy as sp
import glob
import matplotlib.pyplot as plt

CONFU = glob.glob('confu_20*_*.csv')
CONFU.sort()

OA=[]

for confu in CONFU:
    temp = sp.genfromtxt(confu,delimiter=',',skip_header=2)
    OA.append(100.0*sp.diag(temp).sum()/temp.sum())
ind = sp.argmax(OA)

# plot the result
plt.plot(OA)
plt.plot(ind,OA[ind],'sk')
plt.title('Best couples of dates: ' + CONFU[ind])
plt.show()
#+END_SRC

#+BEGIN_SRC r
LISTE=list.files(pattern='confu_')
n=length(LISTE)
OA=array(dim=n)
for(i in 1:n){
  nom=LISTE[i]
  mat <- as.matrix(read.csv(nom, header=FALSE, comment.char="#"))
  OA[i]=sum(diag(mat))/sum(mat)
}
OA
index=which(OA==max(OA))
LISTE[index]
plot(1:n,OA,type='l',col='red',lwd=2)
points(index,OA[index],pch=19,col='green')

#+END_SRC
** Dynamic Habitat
#+BEGIN_SRC sh
#!/bin/bash

# Decoupe des rasters
for name in *tif
do
    gdal_translate -a_nodata 0 -projwin 517844.362981 6257253.98798 545735.795673 6240635.7476 \
		   -of GTiff ${name} cut_${name}
done

# Temporal Gap filling
for name in cut_serie_spot5_coteaux_green.tif cut_serie_spot5_coteaux_mir.tif cut_serie_spot5_coteaux_nir.tif cut_serie_spot5_coteaux_red.tif
do
    otbcli_ImageTimeSeriesGapFilling -in ${name} -mask cut_serie_spot5_coteaux_NUA.tif -out filtered_${name} -comp 1 -it spline -id dates.txt
done

# Compute the NDVI
for i in `seq 1 15`
do
    # Compute the NDVI
    otbcli_BandMath -il filtered_cut_serie_spot5_coteaux_nir.tif filtered_cut_serie_spot5_coteaux_red.tif -out ndvi_${i}.tif  -exp "(im1b${i}+im2b${i} ==0?0:((im1b${i}-im2b${i})/(im1b${i}+im2b${i})+1)/2)"
done

# Compute the SITS
otbcli_ConcatenateImages -il ndvi_{1..15}.tif -out sits.tif
rm ndvi_*.tif

# Compute the cummulative greenness
otbcli_BandMath -il sits.tif -out cumgreen.tif -exp "im1b1+im1b2+im1b3+im1b4+im1b5+im1b6+im1b7+im1b8+im1b9+im1b10+im1b11+im1b12+im1b13+im1b14+im1b15"

# Compute the minimal annual cover
otbcli_BandMath -il sits.tif -out mincover.tif -exp "min(im1b1,im1b2,im1b3,im1b4,im1b5,im1b6,im1b7,im1b8,im1b9,im1b10,im1b11,im1b12,im1b13,im1b14,im1b15)"

# Compute the seasonnal variation
otbcli_BandMath -il sits.tif cumgreen.tif -out seasonvar.tif -exp "sqrt(((im2b1/15-im1b1)^2+(im2b1/15-im1b2)^2+(im2b1/15-im1b3)^2+(im2b1/15-im1b4)^2+(im2b1/15-im1b5)^2+(im2b1/15-im1b6)^2+(im2b1/15-im1b7)^2+(im2b1/15-im1b8)^2+(im2b1/15-im1b9)^2+(im2b1/15-im1b10)^2+(im2b1/15-im1b11)^2+(im2b1/15-im1b12)^2+(im2b1/15-im1b13)^2+(im2b1/15-im1b14)^2+(im2b1/15-im1b15)^2)/15)/im2b1*15"

# Create a multiband images stacking all the three indices
otbcli_ConcatenateImages -il cumgreen.tif mincover.tif seasonvar.tif -out temp.tif

# Rescale value between -1 and 1 for each spectral bands
otbcli_Rescale -in temp.tif -out stack.tif -outmin -1 -outmax 1
rm temp.tif

# Apply KMEANS classification for different number of classes
for classe in {1..10}
do
    otbcli_KMeansClassification -in stack.tif -ts 1000000 -out kmean_${classe}.tif -nc ${classe} -ram 2048 -outmeans centroids_${classe}
done
#+END_SRC
** Python
*** Display image
#+BEGIN_SRC python :tanlg
import matplotlib.pyplot as plt
import scipy as sp
import myfilters as mf
# Load image
# image = sp.load("/home/mfauvel/Documents/Enseignement/ENSAT/Master SIGMA/Documents/TP/python/ikonos_part.npy")
image = sp.load("/home/mfauvel/Documents/Enseignement/ENSAT/Master SIGMA/Documents/TP/python/ikonos_part_sp.npy")

plt.figure()
plt.imshow(image,cmap="gray")

# # Filter max
# plt.figure()
# filmax = mf.filterMax(image,p=1)
# plt.imshow(filmax,cmap="gray")

# plt.figure()
# filmin = mf.filterMin(image,p=1)
# plt.imshow(filmin,cmap="gray")

# plt.figure()
# filmedian = mf.filterMedian(image,p=1)
# plt.imshow(filmedian,cmap="gray")

# plt.figure()
# filmean = mf.filterMean(image,p=1)
# plt.imshow(filmean,cmap="gray")

for p in range(1,6):
    plt.figure()
    out = mf.filterMedian(image,p=p)
    plt.imshow(out,cmap="gray")
plt.show()
#+END_SRC

#+RESULTS:
: None
*** Template filters
#+BEGIN_SRC python :tangle myfilters.py
import scipy as sp

def filterMax(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=imin[(i-p):(i+p+1),(j-p):(j+p+1)].max()

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout

def filterMin(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=imin[(i-p):(i+p+1),(j-p):(j+p+1)].min()

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout

def filterMean(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=imin[(i-p):(i+p+1),(j-p):(j+p+1)].mean()

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout

def filterMedian(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=sp.median(imin[(i-p):(i+p+1),(j-p):(j+p+1)])

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout


def filterMulti(imin,p=1,filter='median'):
    """This  function apply  the  filter  on data cube

    Input:
    -----
    imin = image to be processed, Scipy 3D-Array
    p = window size = 2p+1. Should be strictly positive
    filter = the kind of filter
    Output:
    ------    
    imout = filtered image, Scipy 3D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    H,W,D = imin.shape # Get the image shape
    
    imout = sp.empty((H,W,D),dtype=imin.dtype) # Initialization of the output image

    # Select the filter
    if filter == 'max':
        function = filterMax
    elif filter == 'min':
        function = filterMin
    elif filter == 'mean':
        function = filterMean
    else :
        function = filterMedian

    for d in range(D):
        imout[:,:,d]=function(imin[:,:,d],p=p)

    return imout
    
#+END_SRC

*** +Test speed+

#+BEGIN_SRC python :results output
import myfilters as mf
import time
import scipy as sp

# Load image
image = sp.load("/home/mfauvel/Documents/Enseignement/ENSAT/Master SIGMA/Documents/TP/python/ikonos_part.npy")

# 
tic = time.time()
im1 = mf.filterMax(image,p=1)
print "Processing time : {}".format(time.time()-tic)

tic = time.time()
im1 = mf.filterMaxS(image,p=1)
print "Processing time : {}".format(time.time()-tic)
#+END_SRC

#+RESULTS:
: Processing time : 0.954054117203
: Processing time : 0.926885128021

*** Load/Write raster
#+BEGIN_SRC python :tangle rasterTool.py
import scipy as sp
from osgeo import gdal

def open_data(filename):
    '''
    The function open and load the image given its name. 
    The type of the data is checked from the file and the scipy array is initialized accordingly.
    Input:
        filename: the name of the file
    Output:
        im: the data cube
        GeoTransform: the geotransform information 
        Projection: the projection information
    '''
    data = gdal.Open(filename,gdal.GA_ReadOnly)
    if data is None:
        print 'Impossible to open '+filename
        exit()
    nc = data.RasterXSize
    nl = data.RasterYSize
    d  = data.RasterCount
    
    # Get the type of the data
    gdal_dt = data.GetRasterBand(1).DataType
    if gdal_dt == gdal.GDT_Byte:
        dt = 'uint8'
    elif gdal_dt == gdal.GDT_Int16:
        dt = 'int16'
    elif gdal_dt == gdal.GDT_UInt16:
        dt = 'uint16'
    elif gdal_dt == gdal.GDT_Int32:
        dt = 'int32'
    elif gdal_dt == gdal.GDT_UInt32:
        dt = 'uint32'
    elif gdal_dt == gdal.GDT_Float32:
        dt = 'float32'
    elif gdal_dt == gdal.GDT_Float64:
        dt = 'float64'
    elif gdal_dt == gdal.GDT_CInt16 or gdal_dt == gdal.GDT_CInt32 or gdal_dt == gdal.GDT_CFloat32 or gdal_dt == gdal.GDT_CFloat64 :
        dt = 'complex64'
    else:
        print 'Data type unkown'
        exit()
    
    # Initialize the array
    if d ==1:
        im = sp.empty((nl,nc),dtype=dt)
        im =data.GetRasterBand(1).ReadAsArray()
    else:
        im = sp.empty((nl,nc,d),dtype=dt) 
        for i in range(d):
            im[:,:,i]=data.GetRasterBand(i+1).ReadAsArray()

   
    GeoTransform = data.GetGeoTransform()
    Projection = data.GetProjection()
    data = None # Close the file
    return im,GeoTransform,Projection

def write_data(outname,im,GeoTransform,Projection):
    '''
    The function write the image on the  hard drive.
    Input: 
        outname: the name of the file to be written
        im: the image cube
        GeoTransform: the geotransform information 
        Projection: the projection information
    Output:
        Nothing --
    '''
    nl = im.shape[0]
    nc = im.shape[1]
    if im.ndim == 2:
        d=1
    else:
        d = im.shape[2]
    
    driver = gdal.GetDriverByName('GTiff')
    dt = im.dtype.name
    # Get the data type
    if dt == 'bool' or dt == 'uint8':
        gdal_dt=gdal.GDT_Byte
    elif dt == 'int8' or dt == 'int16':
        gdal_dt=gdal.GDT_Int16
    elif dt == 'uint16':
        gdal_dt=gdal.GDT_UInt16
    elif dt == 'int32':
        gdal_dt=gdal.GDT_Int32
    elif dt == 'uint32':
        gdal_dt=gdal.GDT_UInt32
    elif dt == 'int64' or dt == 'uint64' or dt == 'float16' or dt == 'float32':
        gdal_dt=gdal.GDT_Float32
    elif dt == 'float64':
        gdal_dt=gdal.GDT_Float64
    elif dt == 'complex64':
        gdal_dt=gdal.GDT_CFloat64
    else:
        print 'Data type non-suported'
        exit()
    
    dst_ds = driver.Create(outname,nc,nl, d, gdal_dt)
    dst_ds.SetGeoTransform(GeoTransform)
    dst_ds.SetProjection(Projection)
    
    if d==1:
        out = dst_ds.GetRasterBand(1)
        out.WriteArray(im)
        out.FlushCache()
    else:
        for i in range(d):
            out = dst_ds.GetRasterBand(i+1)
            out.WriteArray(im[:,:,i])
            out.FlushCache()
    dst_ds = None # Close the file
    out = None
#+END_SRC
*** HM
#+BEGIN_SRC python :tangle test_hm.py
import myfilters as mf
import rasterTool as rt

p= 10

# load data
im,geo,proj = rt.open_data("/tmp/decoup.tif")
print im.shape

# filter
im_fmax = mf.filterMulti(im,p=p,filter='max')
del im

im_fmin = mf.filterMulti(im_fmax,p=p,filter='min')
del im_fmax

im_fmedian = mf.filterMulti(im_fmin,p=p,filter='median')
del im_fmin

# save data
outname = "/tmp/toto_"+str(p) +".tif"
rt.write_data(outname,im_fmedian,geo,proj)
#+END_SRC
*** Parser
#+BEGIN_SRC python :tangle parse_hm.py
import myfilters as mf
import rasterTool as rt
import argparse

# Initialize parser
parser = argparse.ArgumentParser()

# Add arguments
parser.add_argument("-in",dest="imageIn",help="Image to be processed",type=str,default=None)
parser.add_argument("-out",dest="imageOut",help="Image processed",type=str,default=None)
parser.add_argument("-p",help="Size of the template",type=int,default=1)

args = parser.parse_args()

# Some tests
if args.imageIn == None:
    exit()

# load data
im,geo,proj = rt.open_data(args.imageIn)
print im.shape

# filter
im_fmax = mf.filterMulti(im,p=args.p,filter='max')
del im

im_fmin = mf.filterMulti(im_fmax,p=args.p,filter='min')
del im_fmax

im_fmedian = mf.filterMulti(im_fmin,p=args.p,filter='median')
del im_fmin

# save data
rt.write_data(args.imageOut,im_fmedian,geo,proj)
#+END_SRC
*** QGIS Script
#+BEGIN_SRC python :tangle qgis_script.py
from PyQt4.QtCore import *
from PyQt4.QtGui import *
from qgis.core import *
from qgis.gui import *


import scipy as sp
from osgeo import gdal
## FILTERS
def filterMax(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=imin[(i-p):(i+p+1),(j-p):(j+p+1)].max()

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout

def filterMin(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=imin[(i-p):(i+p+1),(j-p):(j+p+1)].min()

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout

def filterMean(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=imin[(i-p):(i+p+1),(j-p):(j+p+1)].mean()

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout

def filterMedian(imin,p=1):
    """This  function apply  the  filter  TheFilter  on image imin  with
    parameters p1, p2, ...p2

    Input:
    -----
    imin = image to be processed, Scipy 2D-Array
    p = window size = 2p+1. Should be strictly positive

    Output:
    ------    
    imout = filtered image, Scipy 2D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    ## Initialization
    if imin.ndim != 2: # Check  the number of dimensions of the image:
                       # should be 2
        return 0
    
    H,W = imin.shape # Get the image shape

    imout = sp.empty((H,W),dtype=imin.dtype) # Initialization of the output image
    ## Size of the window
    if p<=0:
        return 0
    
    ## Loop over the pixels
    for i in range(p,H-p):
        for j in range(p,W-p):
            imout[i,j]=sp.median(imin[(i-p):(i+p+1),(j-p):(j+p+1)])

    ## Fill border
    imout[:,:p]=imin[:,:p]
    imout[:,-p:]=imin[:,-p:]
    imout[:p,:]=imin[:p,:]
    imout[-p:,:]=imin[-p:,:]
    
    return imout


def filterMulti(imin,p=1,filter='median'):
    """This  function apply  the  filter  on data cube

    Input:
    -----
    imin = image to be processed, Scipy 3D-Array
    p = window size = 2p+1. Should be strictly positive
    filter = the kind of filter
    Output:
    ------    
    imout = filtered image, Scipy 3D-Array, not necessraly of the same
    type as imin, depending of the filter
    """
    H,W,D = imin.shape # Get the image shape
    
    imout = sp.empty((H,W,D),dtype=imin.dtype) # Initialization of the output image

    # Select the filter
    if filter == 'max':
        function = filterMax
    elif filter == 'min':
        function = filterMin
    elif filter == 'mean':
        function = filterMean
    else :
        function = filterMedian

    for d in range(D):
        imout[:,:,d]=function(imin[:,:,d],p=p)

    return imout
    

## RASTER TOOL
def open_data(filename):
    '''
    The function open and load the image given its name. 
    The type of the data is checked from the file and the scipy array is initialized accordingly.
    Input:
        filename: the name of the file
    Output:
        im: the data cube
        GeoTransform: the geotransform information 
        Projection: the projection information
    '''
    data = gdal.Open(filename,gdal.GA_ReadOnly)
    if data is None:
        print 'Impossible to open '+filename
        exit()
    nc = data.RasterXSize
    nl = data.RasterYSize
    d  = data.RasterCount
    
    # Get the type of the data
    gdal_dt = data.GetRasterBand(1).DataType
    if gdal_dt == gdal.GDT_Byte:
        dt = 'uint8'
    elif gdal_dt == gdal.GDT_Int16:
        dt = 'int16'
    elif gdal_dt == gdal.GDT_UInt16:
        dt = 'uint16'
    elif gdal_dt == gdal.GDT_Int32:
        dt = 'int32'
    elif gdal_dt == gdal.GDT_UInt32:
        dt = 'uint32'
    elif gdal_dt == gdal.GDT_Float32:
        dt = 'float32'
    elif gdal_dt == gdal.GDT_Float64:
        dt = 'float64'
    elif gdal_dt == gdal.GDT_CInt16 or gdal_dt == gdal.GDT_CInt32 or gdal_dt == gdal.GDT_CFloat32 or gdal_dt == gdal.GDT_CFloat64 :
        dt = 'complex64'
    else:
        print 'Data type unkown'
        exit()
    
    # Initialize the array
    if d ==1:
        im = sp.empty((nl,nc),dtype=dt)
        im =data.GetRasterBand(1).ReadAsArray()
    else:
        im = sp.empty((nl,nc,d),dtype=dt) 
        for i in range(d):
            im[:,:,i]=data.GetRasterBand(i+1).ReadAsArray()

   
    GeoTransform = data.GetGeoTransform()
    Projection = data.GetProjection()
    data = None # Close the file
    return im,GeoTransform,Projection

def write_data(outname,im,GeoTransform,Projection):
    '''
    The function write the image on the  hard drive.
    Input: 
        outname: the name of the file to be written
        im: the image cube
        GeoTransform: the geotransform information 
        Projection: the projection information
    Output:
        Nothing --
    '''
    nl = im.shape[0]
    nc = im.shape[1]
    if im.ndim == 2:
        d=1
    else:
        d = im.shape[2]
    
    driver = gdal.GetDriverByName('GTiff')
    dt = im.dtype.name
    # Get the data type
    if dt == 'bool' or dt == 'uint8':
        gdal_dt=gdal.GDT_Byte
    elif dt == 'int8' or dt == 'int16':
        gdal_dt=gdal.GDT_Int16
    elif dt == 'uint16':
        gdal_dt=gdal.GDT_UInt16
    elif dt == 'int32':
        gdal_dt=gdal.GDT_Int32
    elif dt == 'uint32':
        gdal_dt=gdal.GDT_UInt32
    elif dt == 'int64' or dt == 'uint64' or dt == 'float16' or dt == 'float32':
        gdal_dt=gdal.GDT_Float32
    elif dt == 'float64':
        gdal_dt=gdal.GDT_Float64
    elif dt == 'complex64':
        gdal_dt=gdal.GDT_CFloat64
    else:
        print 'Data type non-suported'
        exit()
    
    dst_ds = driver.Create(outname,nc,nl, d, gdal_dt)
    dst_ds.SetGeoTransform(GeoTransform)
    dst_ds.SetProjection(Projection)
    
    if d==1:
        out = dst_ds.GetRasterBand(1)
        out.WriteArray(im)
        out.FlushCache()
    else:
        for i in range(d):
            out = dst_ds.GetRasterBand(i+1)
            out.WriteArray(im[:,:,i])
            out.FlushCache()
    dst_ds = None # Close the file
    out = None

## The core function
def run_script(iface,p,output_name):

    ## Get the filename of the data to be processed
    layer = iface.activeLayer() # Get the current layer
    name = layer.dataProvider().dataSourceUri() # Get the path of the layer

    ## Do the processing (copy/paste from previous function)
    # load data
    im,geo,proj = open_data(name)
        
    # filter
    im_fmax = filterMulti(im,p=p,filter='max')
    del im
    
    im_fmin = filterMulti(im_fmax,p=p,filter='min')
    del im_fmax
    
    im_fmedian = filterMulti(im_fmin,p=p,filter='median')
    del im_fmin
    
    # save data
    write_data(output_name,im_fmedian,geo,proj)

    # Load data into QGIS
    raster_lyr = iface.addRasterLayer(output_name,'FilterImage')
#+END_SRC
* TO DO                                                            :noexport:
** A complÃ©ter
- [X] Ecrire le fonctionnement des TD
- [ ] Faire un mind map
- [X] PrÃ©sentation des scripts shell
- [X] Reprendres les objectifs pour les compÃ©tences plutot que pour
  les activitÃ©s
- [X] Faire la carte "test" pour la spatilization
- [ ] Leur faire faire une carte sur Fabas pour FranÃ§ois.
- [X] Faire le script pour les rÃ©sultats de classifications et multitemp
- [100%] Rajouter le dÃ©tails des bandes dans la section Data sets
  - [X] SITS
  - [X] Change detection
- [ ] Mettre l'images HM en ligne
- [X] Mettre les codes python pour l'ouverture des images, en enlevant les commentaires.
- [X] Faire codes pour tester les temps de calculs sur le parcours des boucles
- [X] Rajouter intro argparss
- [ ] Refaire les box-plots par bande plutot que par classe
- [ ] Ecrire une syntaxe sur Band Math
  + OpÃ©ration classique
  + Comparaison "if" etc ...
  + 
- [ ] Modifier la partie [[#sec:classif:automatize]] pour la partie python, utiliser les commandes internes.
** SÃ©quences plus ou moins prÃªtes
+ [X] Ouvertures et Visualisation d'images
+ [X] Segmentation d'images
+ [X] Spectral indices
+ [X] Construction de sÃ©rie temporelle
+ [X] Changes detection
+ [X] Classification of remote sensing images
+ [ ] +Python: intro aux traitements d'images+
+ [X] Historical Maps
** SÃ©quences en non prÃ©sentielle
- Segmentation of 2D histograms ?
- Classification of images for FranÃ§ois.
- *Influence of the spatial correlation for training/testing set*
- *Get the best dates or couple of date for the classification of SITS ?*
** TODO A modifier
- [X] script python, c'est de la merde :(
- [X] Collecter l'ensemble des solutions pour les scripts
- [X] Donner les bandes pour Fabas et les autres images
- [X] Modifier les images quickbird pour virer la bandes zeros Ã  la fin...
- [X] Rajouter les bandes spectrales pour SITS
- [X] Rajouter le traitement par lots dans QGIS 
  https://docs.qgis.org/2.14/fr/docs/user_manual/processing/batch.html?highlight=batch
- [ ] Sequence en Non presentiel pour le Dynamic Habitat Index

** Column view
#+BEGIN: columnview :hlines 2 :id global :skip-empty-rows t
| ITEM                                                          | FORMATION      | DURATION | SEQUENCE | TAG |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Introduction                                                  | Presential     |     0:30 |        1 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Data sets                                                     | Presential     |        0 |          |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Visualization of remote sensing data                          | Presential     |     1:10 |        1 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Spectral indices: /Normalized Difference Vegetation Index/    | Presential     |    01:00 |        2 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Segmentation of remote sensing images                         | Presential     |     2:00 |        2 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Change detection: /Detection of floods/                       | Presential     |    01:40 |        3 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Classification of remote sensing images                       | Presential     |    04:00 |      3-4 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Influence of the spatial distribution of the learning samples | Non Presential |    01:00 |        4 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Satellite Image Time Series                                   | Presential     |    04:00 |      4-5 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Extraction of the best couple of dates                        | Non Presential |    01:40 |          |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Dynamic Habitat Index                                         | Presential     |    04:00 |        5 |     |
|---------------------------------------------------------------+----------------+----------+----------+-----|
| Template filters                                              | Presential     |    04:00 |          |     |
#+END:

